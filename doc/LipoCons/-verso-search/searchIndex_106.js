window.docContents[106].resolve({"/Consistency-equivalence/#Consistency-of-global-optimization-algorithms--Consistency-equivalence":{"contents":"We prove the equivalence between  and  for any stochastic iterative global optimization  A. This corresponds to Proposition 3 of the paper .\n\n\n\nThe proof of the proposition is available in the ArXiv preprint of the original paper . We follow the same structure while adapting the proof to the Lean formalization. We also fixed a small mistake in the original proof, which was pointed out to the authors in a private discussion.\n\nThe modus ponens direction is easy to prove, as the continuity of f implies that sequences of samples such that, the maximum of their evaluations under f is at least \\varepsilon, do not belong to a ball centered on the maximum of f with positive radius. The  hypothesis implies that the set of such sequences has measure tending to 0 as n tends to infinity, which proves .\n\nThe converse direction is more involved. The proof is done by contradiction: if the algorithm does not sample the whole space for a given function f, then there exists a ball such that the measure of the set of sequences of samples that do not belong to this ball does not tend to 0 as n tends to infinity. The idea is to construct a function \\tilde{f} that is indistinguishable from f outside of this ball, such that the maximum of \\tilde{f} is strictly greater than the maximum of f and such that the \\arg \\max of \\tilde{f} is inside the ball. This contradicts the  hypothesis, as the maximum of \\tilde{f} is almost never sampled by the algorithm.\n\nOur construction of the function \\tilde{f} has a slightly simpler expression than the one in the original paper but provides the same properties. For more details, see Indistinguishable function.\n\n\n","context":"Consistency of global optimization algorithms","header":"3. Consistency equivalence","id":"/Consistency-equivalence/#Consistency-of-global-optimization-algorithms--Consistency-equivalence"}});