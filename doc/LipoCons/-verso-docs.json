{"99":
 "<code>Dist.dist.{u_3} {α : Type u_3} [self : Dist α] : α → α → ℝ</code><span class=\"sep\"></span><code class=\"docstring\">Distance between two points </code>",
 "98": "<code>ℝ</code>",
 "97":
 "<code>Lipschitz.{u_1, u_2} {α : Type u_1} {β : Type u_2} [PseudoEMetricSpace α] [PseudoEMetricSpace β] (f : α → β) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">A wrapper around `LipschitzWith` of Mathlib. A function is `Lipschitz` if it exists\na `K : ℝ≥0` such that `LipschitzWith K f`. </code>",
 "96": "<code>Lipschitz f</code>",
 "95":
 "<code>set_dist_max.{u_1, u_2} {α : Type u_1} [PseudoMetricSpace α] [CompactSpace α] [Nonempty α] {β : Type u_2} [Nonempty β]\n  [PseudoMetricSpace β] [LinearOrder β] [ClosedIciTopology β] {f : α → β} (hf : Lipschitz f) {n : ℕ} (ε : ℝ) :\n  Set (iter α n)</code><span class=\"sep\"></span><code class=\"docstring\">The set of sequences of size `n + 1` such that the maximum of `f` over\nthese sequences is at least `ε` away from from `fmax`. </code>",
 "94":
 "<code>fmax.{u_1, u_2} {α : Type u_1} [PseudoMetricSpace α] [CompactSpace α] [Nonempty α] {β : Type u_2} [PseudoMetricSpace β]\n  [LinearOrder β] [ClosedIciTopology β] {f : α → β} (hf : Lipschitz f) : β</code><span class=\"sep\"></span><code class=\"docstring\">The maximum of a Lipschitz function over `α`. </code>",
 "93":
 "<code>Algorithm.measure.{u_1, u_2} {α : Type u_1} {β : Type u_2} [MeasurableSpace α] [TopologicalSpace α]\n  [OpensMeasurableSpace α] [MeasurableSpace β] [TopologicalSpace β] [BorelSpace β] (A : Algorithm α β) {f : α → β}\n  (hf : Continuous f) (n : ℕ) : MeasureTheory.Measure (iter α n)</code><span class=\"sep\"></span><code class=\"docstring\">Given a continuous evaluation function `f : α → β`, this defines\nthe joint distribution over the sequence of proposed points\nup to iteration `n`, as a measure on `iter α n`.\n\nThe construction is recursive:\n- At step `n = 0`, the measure is the initial distribution `ν`, viewed as a constant sequence of length 1.\n- At step `n + 1`, the measure is obtained by applying the algorithm's transition kernel\n  (with evaluations computed via `f`) to extend the previous history by one point.\n\nThe function `next_measure` performs this step, using `iter_comap` to inject evaluations into\nthe kernel’s input space.\n\nThis defines the full law of the trajectory of proposed points, up to time `n`. </code>",
 "92": "<code>Fin (n + 1)</code>",
 "91":
 "<code>Set.pi.{u_1, u_2} {ι : Type u_1} {α : ι → Type u_2} (s : Set ι) (t : (i : ι) → Set (α i)) : Set ((i : ι) → α i)</code><span class=\"sep\"></span><code class=\"docstring\">Given an index set `ι` and a family of sets `t : Π i, Set (α i)`, `pi s t`\nis the set of dependent functions `f : Πa, π a` such that `f i` belongs to `t i`\nwhenever `i ∈ s`. </code>",
 "90":
 "<code>Set.univ.{u} {α : Type u} : Set α</code><span class=\"sep\"></span><code class=\"docstring\">The universal set on a type `α` is the set containing all elements of `α`.\n\nThis is conceptually the \"same as\" `α` (in set theory, it is actually the same), but type theory\nmakes the distinction that `α` is a type while `Set.univ` is a term of type `Set α`. `Set.univ` can\nitself be coerced to a type `↥Set.univ` which is in bijection with (but distinct from) `α`. </code>",
 "9": "<code>Measure α</code>",
 "89":
 "<code>MeasureTheory.Measure.restrict.{u_2} {α : Type u_2} {_m0 : MeasurableSpace α} (μ : Measure α) (s : Set α) : Measure α</code><span class=\"sep\"></span><code class=\"docstring\">Restrict a measure `μ` to a set `s`. </code>",
 "88":
 "<code>Set.restrict.{u_1, u_6} {α : Type u_1} {π : α → Type u_6} (s : Set α) (f : (a : α) → π a) (a : ↑s) : π ↑a</code><span class=\"sep\"></span><code class=\"docstring\">Restrict domain of a function `f` to a set `s`. Same as `Subtype.restrict` but this version\ntakes an argument `↥s` instead of `Subtype s`. </code>",
 "87": "<code>s.restrict f = s.restrict g</code>",
 "86": "<code>Set α</code>",
 "85": "<code>Continuous g</code>",
 "84":
 "<code>Algorithm.eq_restrict.{u_1, u_2} {α : Type u_1} {β : Type u_2} [MeasurableSpace α] [TopologicalSpace α]\n  [OpensMeasurableSpace α] [MeasurableSpace β] [TopologicalSpace β] [BorelSpace β] (A : Algorithm α β) {f g : α → β}\n  (hf : Continuous f) (hg : Continuous g) {s : Set α} (hs : MeasurableSet s) (h : s.restrict f = s.restrict g) (n : ℕ) :\n  (A.measure hf n).restrict (univ.pi fun x =&gt; s) = (A.measure hg n).restrict (univ.pi fun x =&gt; s)</code><span class=\"sep\"></span><code class=\"docstring\">If two continuous functions `f` and `g` agree on a measurable set `s`, then the algorithm's\ninduced measures at iteration `n` are identical when restricted to trajectories that stay\nwithin `s`. This establishes that the algorithm depends only on the objective function values\non the relevant domain. </code>",
 "83":
 "<code>Membership.mem.{u, v} {α : outParam (Type u)} {γ : Type v} [self : Membership α γ] : γ → α → Prop</code><span class=\"sep\"></span><code class=\"docstring\">The membership relation `a ∈ s : Prop` where `a : α`, `s : γ`. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `∈` in identifiers is `mem`.</code>",
 "82":
 "<code>setOf.{u} {α : Type u} (p : α → Prop) : Set α</code><span class=\"sep\"></span><code class=\"docstring\">Turn a predicate `p : α → Prop` into a set, also written as `{x | p x}` </code>",
 "81":
 "<code>HasSubset.Subset.{u} {α : Type u} [self : HasSubset α] : α → α → Prop</code><span class=\"sep\"></span><code class=\"docstring\">Subset relation: `a ⊆ b`  \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `⊆` in identifiers is `subset`.</code>",
 "80":
 "<code>LE.le.{u} {α : Type u} [self : LE α] : α → α → Prop</code><span class=\"sep\"></span><code class=\"docstring\">The less-equal relation: `x ≤ y` \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `≤` in identifiers is `le`.\n\n * The recommended spelling of `&lt;=` in identifiers is `le` (prefer `≤` over `&lt;=`).</code>",
 "8":
 "<code>MeasureTheory.IsProbabilityMeasure.{u_1} {α : Type u_1} {m0 : MeasurableSpace α} (μ : Measure α) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">A measure `μ` is called a probability measure if `μ univ = 1`. </code>",
 "79":
 "<code>Tuple.subTuple.{u_1} {α : Type u_1} {n m : ℕ} (hmn : n ≤ m) (u : Fin (m + 1) → α) : Fin (n + 1) → α</code><span class=\"sep\"></span><code class=\"docstring\">Given `n ≤ m`, this is the restriction of a function `u : Fin (m + 1) → α`\nto a function `Fin (n + 1) → α`. </code>",
 "78": "<code>iter α m</code>",
 "77": "<code>e ⊆ {u | subTuple hmn u ∈ s}</code>",
 "76": "<code>n ≤ m</code>",
 "75": "<code>Set (iter α m)</code>",
 "74": "<code>Set (iter α n)</code>",
 "73":
 "<code>Algorithm.mono.{u_1, u_2} {α : Type u_1} {β : Type u_2} [MeasurableSpace α] [TopologicalSpace α]\n  [OpensMeasurableSpace α] [MeasurableSpace β] [TopologicalSpace β] [BorelSpace β] (A : Algorithm α β) {n m : ℕ}\n  {s : Set (iter α n)} (hs : MeasurableSet s) {e : Set (iter α m)} (hmn : n ≤ m) (hse : e ⊆ {u | subTuple hmn u ∈ s})\n  {f : α → β} (hf : Continuous f) : (A.measure hf m) e ≤ (A.measure hf n) s</code><span class=\"sep\"></span><code class=\"docstring\">Monotonicity of the algorithm's induced measures under trajectory extension.\n\nLet `s : Set iter α n` be a measurable set of point sequences of length `n`,\nand `e : Set iter α m` for some `m ≥ n` a set of longer trajectories such that\nevery `u ∈ e` satisfies `subTuple hmn u ∈ s`.\n\nThen the measure assigned to `e` by the algorithm at step `m` is less than or equal to\nthe measure assigned to `s` at step `n`.\n\nThis expresses that the family of measures is projectively consistent:\nthe measure on longer trajectories contracts to the measure on shorter ones via truncation.\n\nFormally: if `e ⊆ {u | subTuple hmn u ∈ s}`, then `A.measure hf m e ≤ A.measure hf n s`. </code>",
 "72":
 "<code class=\"docstring\">`exact e` closes the main goal if its target type matches that of `e`.\n</code>",
 "71":
 "<code>Nat.succ (n : ℕ) : ℕ</code><span class=\"sep\"></span><code class=\"docstring\">The successor of a natural number `n`.\n\nUsing `Nat.succ n` should usually be avoided in favor of `n + 1`, which is the [simp normal\nform](https://lean-lang.org/doc/reference/4.22.0-rc3/find/?domain=Verso.Genre.Manual.section&name=simp-normal-forms).\n</code>",
 "70":
 "<code>Nat.pred : ℕ → ℕ</code><span class=\"sep\"></span><code class=\"docstring\">The predecessor of a natural number is one less than it. The predecessor of `0` is defined to be\n`0`.\n\nThis definition is overridden in the compiler with an efficient implementation. This definition is\nthe logical model.\n</code>",
 "7":
 "<code>Algorithm.prob_measure.{u_1, u_2} {α : Type u_1} {β : Type u_2} [MeasurableSpace α] [MeasurableSpace β]\n  (self : Algorithm α β) : IsProbabilityMeasure self.ν</code>",
 "69":
 "<code>Nat.succ_pred_eq_of_ne_zero {n : ℕ} : n ≠ 0 → n.pred.succ = n</code>",
 "68":
 "<code class=\"docstring\">`rw` is like `rewrite`, but also tries to close the goal by \"cheap\" (reducible) `rfl` afterwards.\n</code>",
 "67":
 "<code>Not (a : Prop) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">`Not p`, or `¬p`, is the negation of `p`. It is defined to be `p → False`,\nso if your goal is `¬p` you can use `intro h` to turn the goal into\n`h : p ⊢ False`, and if you have `hn : ¬p` and `h : p` then `hn h : False`\nand `(hn h).elim` will prove anything.\nFor more information: [Propositional Logic](https://lean-lang.org/theorem_proving_in_lean4/propositions_and_proofs.html#propositional-logic)\n\n\nConventions for notations in identifiers:\n\n * The recommended spelling of `¬` in identifiers is `not`.</code>",
 "66": "<code>¬n = 0</code>",
 "65":
 "<code>MeasureTheory.Measure.pi.{u_4, u_5} {ι : Type u_4} {α : ι → Type u_5} [Fintype ι] [(i : ι) → MeasurableSpace (α i)]\n  (μ : (i : ι) → Measure (α i)) : Measure ((i : ι) → α i)</code><span class=\"sep\"></span><code class=\"docstring\">`Measure.pi μ` is the finite product of the measures `{μ i | i : ι}`.\nIt is defined to be measure corresponding to `MeasureTheory.OuterMeasure.pi`. </code>",
 "64": "<code>n = 0</code>",
 "63":
 "<code class=\"docstring\">\"Dependent\" if-then-else, normally written via the notation `if h : c then t(h) else e(h)`,\nis sugar for `dite c (fun h =&gt; t(h)) (fun h =&gt; e(h))`, and it is the same as\n`if c then t else e` except that `t` is allowed to depend on a proof `h : c`,\nand `e` can depend on `h : ¬c`. (Both branches use the same name for the hypothesis,\neven though it has different types in the two cases.)\n\nWe use this to be able to communicate the if-then-else condition to the branches.\nFor example, `Array.get arr i h` expects a proof `h : i &lt; arr.size` in order to\navoid a bounds check, so you can write `if h : i &lt; arr.size then arr.get i h else ...`\nto avoid the bounds check inside the if branch. (Of course in this case we have only\nlifted the check into an explicit `if`, but we could also use this proof multiple times\nor derive `i &lt; arr.size` from some other proposition that we are checking in the `if`.)\n</code>",
 "62":
 "<code>Algorithm.measure.{u_1, u_2} {α : Type u_1} {β : Type u_2} [MeasurableSpace α] [TopologicalSpace α]\n  [OpensMeasurableSpace α] [MeasurableSpace β] [TopologicalSpace β] [BorelSpace β] (A : Algorithm α β) {f : α → β}\n  (hf : Continuous f) (n : ℕ) : Measure (iter α n)</code><span class=\"sep\"></span><code class=\"docstring\">Given a continuous evaluation function `f : α → β`, this defines\nthe joint distribution over the sequence of proposed points\nup to iteration `n`, as a measure on `iter α n`.\n\nThe construction is recursive:\n- At step `n = 0`, the measure is the initial distribution `ν`, viewed as a constant sequence of length 1.\n- At step `n + 1`, the measure is obtained by applying the algorithm's transition kernel\n  (with evaluations computed via `f`) to extend the previous history by one point.\n\nThe function `next_measure` performs this step, using `iter_comap` to inject evaluations into\nthe kernel’s input space.\n\nThis defines the full law of the trajectory of proposed points, up to time `n`. </code>",
 "61":
 "<code>tsum.{u_4, u_5} {α : Type u_4} [AddCommMonoid α] [TopologicalSpace α] {β : Type u_5} (f : β → α) : α</code><span class=\"sep\"></span><code class=\"docstring\">`∑' i, f i` is the sum of `f` if it exists and is unconditionally convergent,\nor 0 otherwise.</code>",
 "60":
 "<code>Disjoint.{u_1} {α : Type u_1} [PartialOrder α] [OrderBot α] (a b : α) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">Two elements of a lattice are disjoint if their inf is the bottom element.\n  (This generalizes disjoint sets, viewed as members of the subset lattice.)\n\nNote that we define this without reference to `⊓`, as this allows us to talk about orders where\nthe infimum is not unique, or where implementing `Inf` would require additional `Decidable`\narguments. </code>",
 "6":
 "<code>MeasureTheory.Measure.{u_6} (α : Type u_6) [MeasurableSpace α] : Type u_6</code><span class=\"sep\"></span><code class=\"docstring\">A measure is defined to be an outer measure that is countably additive on\nmeasurable sets, with the additional assumption that the outer measure is the canonical\nextension of the restricted measure.\n\nThe measure of a set `s`, denoted `μ s`, is an extended nonnegative real. The real-valued version\nis written `μ.real s`.\n</code>",
 "59":
 "<code>Function.onFun.{u₁, u₂, u₃} {α : Sort u₁} {β : Sort u₂} {φ : Sort u₃} (f : β → β → φ) (g : α → β) : α → α → φ</code><span class=\"sep\"></span><code class=\"docstring\">Given functions `f : β → β → φ` and `g : α → β`, produce a function `α → α → φ` that evaluates\n`g` on each argument, then applies `f` to the results. Can be used, e.g., to transfer a relation\nfrom `β` to `α`. </code>",
 "58":
 "<code>Pairwise.{u_1} {α : Type u_1} (r : α → α → Prop) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">A relation `r` holds pairwise if `r i j` for all `i ≠ j`. </code>",
 "57":
 "<code>MeasurableSet.{u_1} {α : Type u_1} [MeasurableSpace α] (s : Set α) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">`MeasurableSet s` means that `s` is measurable (in the ambient measure space on `α`) </code>",
 "56": "<code>∀ (i : ℕ), MeasurableSet (f_1 i)</code>",
 "55":
 "<code>Set.{u} (α : Type u) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">A set is a collection of elements of some type `α`.\n\nAlthough `Set` is defined as `α → Prop`, this is an implementation detail which should not be\nrelied on. Instead, `setOf` and membership of a set (`∈`) should be used to convert between sets\nand predicates.\n</code>",
 "54": "<code>ℕ → Set (iter α (n + 1))</code>",
 "53":
 "<code>Eq.{u_1} {α : Sort u_1} : α → α → Prop</code><span class=\"sep\"></span><code class=\"docstring\">The equality relation. It has one introduction rule, `Eq.refl`.\nWe use `a = b` as notation for `Eq a b`.\nA fundamental property of equality is that it is an equivalence relation.\n```\nvariable (α : Type) (a b c d : α)\nvariable (hab : a = b) (hcb : c = b) (hcd : c = d)\n\nexample : a = d :=\n  Eq.trans (Eq.trans hab (Eq.symm hcb)) hcd\n```\nEquality is much more than an equivalence relation, however. It has the important property that every assertion\nrespects the equivalence, in the sense that we can substitute equal expressions without changing the truth value.\nThat is, given `h1 : a = b` and `h2 : p a`, we can construct a proof for `p b` using substitution: `Eq.subst h1 h2`.\nExample:\n```\nexample (α : Type) (a b : α) (p : α → Prop)\n        (h1 : a = b) (h2 : p a) : p b :=\n  Eq.subst h1 h2\n\nexample (α : Type) (a b : α) (p : α → Prop)\n    (h1 : a = b) (h2 : p a) : p b :=\n  h1 ▸ h2\n```\nThe triangle in the second presentation is a macro built on top of `Eq.subst` and `Eq.symm`, and you can enter it by typing `\\t`.\nFor more information: [Equality](https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#equality)\n\n\nConventions for notations in identifiers:\n\n * The recommended spelling of `=` in identifiers is `eq`.</code>",
 "52":
 "<code>EmptyCollection.emptyCollection.{u} {α : Type u} [self : EmptyCollection α] : α</code><span class=\"sep\"></span><code class=\"docstring\">`∅` or `{}` is the empty set or empty collection.\nIt is supported by the `EmptyCollection` typeclass. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `{}` in identifiers is `empty`.\n\n * The recommended spelling of `∅` in identifiers is `empty`.</code>",
 "51":
 "<code>MeasureTheory.lintegral.{u_4} {α : Type u_4} {m : MeasurableSpace α} (μ : Measure α) (f : α → ℝ≥0∞) : ℝ≥0∞</code><span class=\"sep\"></span><code class=\"docstring\">The **lower Lebesgue integral** of a function `f` with respect to a measure `μ`. </code>",
 "50":
 "<code>Tuple.append.{u_1} {α : Type u_1} {n : ℕ} (u : Fin n → α) (a : α) : Fin (n + 1) → α</code><span class=\"sep\"></span><code class=\"docstring\">Given a function `u : Fin n → α` and an element `a : α`, `append u a` extends\n`u` by one element, i.e., it maps `Fin (n + 1)` to `α` by taking the values of `u`\nand mapping the last index `n` to `a`. </code>",
 "5":
 "<code>Algorithm.ν.{u_1, u_2} {α : Type u_1} {β : Type u_2} [MeasurableSpace α] [MeasurableSpace β] (self : Algorithm α β) :\n  Measure α</code>",
 "49": "<code>iter α (n + 1) → ℝ≥0∞</code>",
 "48":
 "<code>Set.indicator.{u_1, u_3} {α : Type u_1} {M : Type u_3} [Zero M] (s : Set α) (f : α → M) (x : α) : M</code><span class=\"sep\"></span><code class=\"docstring\">`Set.indicator s f a` is `f a` if `a ∈ s`, `0` otherwise.</code>",
 "47": "<code>α</code>",
 "46": "<code>iter α n</code>",
 "45": "<code>MeasurableSet s</code>",
 "44": "<code>Set (iter α (n + 1))</code>",
 "43":
 "<code>MeasureTheory.Measure.ofMeasurable.{u_1} {α : Type u_1} [MeasurableSpace α] (m : (s : Set α) → MeasurableSet s → ℝ≥0∞)\n  (m0 : m ∅ ⋯ = 0)\n  (mU :\n    ∀ ⦃f : ℕ → Set α⦄ (h : ∀ (i : ℕ), MeasurableSet (f i)),\n      Pairwise (Function.onFun Disjoint f) → m (⋃ i, f i) ⋯ = ∑' (i : ℕ), m (f i) ⋯) :\n  Measure α</code><span class=\"sep\"></span><code class=\"docstring\">Obtain a measure by giving a countably additive function that sends `∅` to `0`. </code>",
 "42":
 "<code class=\"docstring\">`refine e` behaves like `exact e`, except that named (`?x`) or unnamed (`?_`)\nholes in `e` that are not solved by unification with the main goal's target type\nare converted into new goals, using the hole's name, if any, as the goal case name.\n</code>",
 "41":
 "<code>HAdd.hAdd.{u, v, w} {α : Type u} {β : Type v} {γ : outParam (Type w)} [self : HAdd α β γ] : α → β → γ</code><span class=\"sep\"></span><code class=\"docstring\">`a + b` computes the sum of `a` and `b`.\nThe meaning of this notation is type-dependent. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `+` in identifiers is `add`.</code>",
 "40":
 "<code>Nat : Type</code><span class=\"sep\"></span><code class=\"docstring\">The natural numbers, starting at zero.\n\nThis type is special-cased by both the kernel and the compiler, and overridden with an efficient\nimplementation. Both use a fast arbitrary-precision arithmetic library (usually\n[GMP](https://gmplib.org/)); at runtime, `Nat` values that are sufficiently small are unboxed.\n</code>",
 "4":
 "<code>MeasurableSpace.{u_7} (α : Type u_7) : Type u_7</code><span class=\"sep\"></span><code class=\"docstring\">A measurable space is a space equipped with a σ-algebra. </code>",
 "39":
 "<code>BorelSpace.{u_6} (α : Type u_6) [TopologicalSpace α] [MeasurableSpace α] : Prop</code><span class=\"sep\"></span><code class=\"docstring\">A space with `MeasurableSpace` and `TopologicalSpace` structures such that\nthe `σ`-algebra of measurable sets is exactly the `σ`-algebra generated by open sets. </code>",
 "38": "<code>BorelSpace β</code>",
 "37": "<code>TopologicalSpace β</code>",
 "36": "<code>MeasurableSpace β</code>",
 "35":
 "<code>OpensMeasurableSpace.{u_6} (α : Type u_6) [TopologicalSpace α] [h : MeasurableSpace α] : Prop</code><span class=\"sep\"></span><code class=\"docstring\">A space with `MeasurableSpace` and `TopologicalSpace` structures such that\nall open sets are measurable. </code>",
 "34": "<code>OpensMeasurableSpace α</code>",
 "33":
 "<code>TopologicalSpace.{u} (X : Type u) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">A topology on `X`. </code>",
 "32": "<code>TopologicalSpace α</code>",
 "31": "<code>MeasurableSpace α</code>",
 "30":
 "<code class=\"docstring\">A type universe. `Type ≡ Type 0`, `Type u ≡ Sort (u + 1)`. </code>",
 "3":
 "<code class=\"docstring\">The syntax `variable (X Y ... Z : Type*)` creates a new distinct implicit universe variable\n`&gt; 0` for each variable in the sequence. </code>",
 "29":
 "<code class=\"docstring\">`by tac` constructs a term of the expected type by running the tactic(s) `tac`. </code>",
 "28": "<code>Measure (iter α n)</code>",
 "27":
 "<code>Algorithm.next_measure.{u_1, u_2} {α : Type u_1} {β : Type u_2} [MeasurableSpace α] [TopologicalSpace α]\n  [OpensMeasurableSpace α] [MeasurableSpace β] [TopologicalSpace β] [BorelSpace β] (A : Algorithm α β) {f : α → β}\n  (hf : Continuous f) {n : ℕ} (μ : Measure (iter α n)) : Measure (iter α (n + 1))</code><span class=\"sep\"></span><code class=\"docstring\">Given:\n- a continuous evaluation function `f : α → β`,\n- a measure `μ` on the space of point histories `iter α n` (i.e., sequences of length `n + 1`),\n\n`next_measure` defines the measure on `iter α (n + 1)` (sequences of length `n + 2`)\nby pushing forward `μ` through the kernel that produces the next point\nconditioned on the current history.\n\nThe kernel is pulled back via `prod_eval n f`, so that evaluations are\ncomputed deterministically from the point history.\n\nThis function corresponds to one step of the recursive construction of the joint distribution\nover the sequence of points generated by the algorithm. </code>",
 "26":
 "<code>Continuous.measurable.{u_1, u_3} {α : Type u_1} {γ : Type u_3} [TopologicalSpace α] [MeasurableSpace α]\n  [OpensMeasurableSpace α] [TopologicalSpace γ] [MeasurableSpace γ] [BorelSpace γ] {f : α → γ} (hf : Continuous f) :\n  Measurable f</code><span class=\"sep\"></span><code class=\"docstring\">A continuous function from an `OpensMeasurableSpace` to a `BorelSpace`\nis measurable. </code>",
 "25":
 "<code>Tuple.measurable_prod_eval.{u_1, u_2} {α : Type u_1} {β : Type u_2} [MeasurableSpace α] [MeasurableSpace β] (n : ℕ)\n  {f : α → β} (hf : Measurable f) : Measurable (prod_eval n f)</code><span class=\"sep\"></span><code class=\"docstring\">For any measurable function `f : α → β`, the function `prod_eval n f` is measurable. </code>",
 "24":
 "<code>Tuple.prod_eval.{u_1, u_2} {α : Type u_1} {β : Type u_2} (n : ℕ) (f : α → β) (u : Fin (n + 1) → α) :\n  (Fin (n + 1) → α) × (Fin (n + 1) → β)</code><span class=\"sep\"></span><code class=\"docstring\">Given `n`, a function `f : α → β` and a function `u : Fin (n + 1) → α`,\nthis is the pair `(u, f ∘ u)`, where `f ∘ u` is the function\nfrom `Fin (n + 1)` to `β` that applies `f` to the values of `u`. </code>",
 "23":
 "<code>ProbabilityTheory.Kernel.comap.{u_1, u_2, u_4} {α : Type u_1} {β : Type u_2} {mα : MeasurableSpace α}\n  {mβ : MeasurableSpace β} {γ : Type u_4} {mγ : MeasurableSpace γ} (κ : Kernel α β) (g : γ → α) (hg : Measurable g) :\n  Kernel γ β</code><span class=\"sep\"></span><code class=\"docstring\">Pullback of a kernel, such that for each set s `comap κ g hg c s = κ (g c) s`.\nWe include measurability in the assumptions instead of using junk values\nto make sure that typeclass inference can infer that the `comap` of a Markov kernel\nis again a Markov kernel. </code>",
 "22": "<code>Algorithm α β</code>",
 "21":
 "<code>iter.{u_1} (α : Type u_1) (n : ℕ) : Type u_1</code><span class=\"sep\"></span><code class=\"docstring\">`iter α n` is the type of finite sequences of elements in `α` of length `n + 1`.\n\nIt represents the history of `n + 1` steps in an iterative process,\nwith entries indexed by `Fin (n + 1)` (i.e., from `0` to `n`).\n\nUsed in the context of stochastic iterative algorithms to store past evaluations or points. </code>",
 "20":
 "<code>Continuous.{u, v} {X : Type u} {Y : Type v} [TopologicalSpace X] [TopologicalSpace Y] (f : X → Y) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">A function between topological spaces is continuous if the preimage\nof every open set is open. Registered as a structure to make sure it is not unfolded by Lean. </code>",
 "2": "<code>Type u_2</code>",
 "19": "<code>Continuous f</code>",
 "18": "<code>α → β</code>",
 "172":
 "<code class=\"docstring\">`linarith` attempts to find a contradiction between hypotheses that are linear (in)equalities.\nEquivalently, it can prove a linear inequality by assuming its negation and proving `False`.\n\nIn theory, `linarith` should prove any goal that is true in the theory of linear arithmetic over\nthe rationals. While there is some special handling for non-dense orders like `Nat` and `Int`,\nthis tactic is not complete for these theories and will not prove every true goal. It will solve\ngoals over arbitrary types that instantiate `LinearOrderedCommRing`.\n\nAn example:\n```lean\nexample (x y z : ℚ) (h1 : 2*x &lt; 3*y) (h2 : -4*x + 2*z &lt; 0)\n        (h3 : 12*y - 4* z &lt; 0) : False := by\n  linarith\n```\n\n`linarith` will use all appropriate hypotheses and the negation of the goal, if applicable.\nDisequality hypotheses require case splitting and are not normally considered\n(see the `splitNe` option below).\n\n`linarith [t1, t2, t3]` will additionally use proof terms `t1, t2, t3`.\n\n`linarith only [h1, h2, h3, t1, t2, t3]` will use only the goal (if relevant), local hypotheses\n`h1`, `h2`, `h3`, and proofs `t1`, `t2`, `t3`. It will ignore the rest of the local context.\n\n`linarith!` will use a stronger reducibility setting to try to identify atoms. For example,\n```lean\nexample (x : ℚ) : id x ≥ x := by\n  linarith\n```\nwill fail, because `linarith` will not identify `x` and `id x`. `linarith!` will.\nThis can sometimes be expensive.\n\n`linarith (config := { .. })` takes a config object with five\noptional arguments:\n* `discharger` specifies a tactic to be used for reducing an algebraic equation in the\n  proof stage. The default is `ring`. Other options include `simp` for basic\n  problems.\n* `transparency` controls how hard `linarith` will try to match atoms to each other. By default\n  it will only unfold `reducible` definitions.\n* If `splitHypotheses` is true, `linarith` will split conjunctions in the context into separate\n  hypotheses.\n* If `splitNe` is `true`, `linarith` will case split on disequality hypotheses.\n  For a given `x ≠ y` hypothesis, `linarith` is run with both `x &lt; y` and `x &gt; y`,\n  and so this runs linarith exponentially many times with respect to the number of\n  disequality hypotheses. (`false` by default.)\n* If `exfalso` is `false`, `linarith` will fail when the goal is neither an inequality nor `False`.\n  (`true` by default.)\n* `restrict_type` (not yet implemented in mathlib4)\n  will only use hypotheses that are inequalities over `tp`. This is useful\n  if you have e.g. both integer and rational valued inequalities in the local context, which can\n  sometimes confuse the tactic.\n\nA variant, `nlinarith`, does some basic preprocessing to handle some nonlinear goals.\n\nThe option `set_option trace.linarith true` will trace certain intermediate stages of the `linarith`\nroutine.\n</code>",
 "171": "<code>fmax hf &lt; fmax ⋯</code>",
 "170":
 "<code>fmax._proof_1.{u_1, u_2} {α : Type u_1} [PseudoMetricSpace α] {β : Type u_2} [PseudoMetricSpace β] {f : α → β}\n  (hf : Lipschitz f) : Continuous f</code>",
 "17":
 "<code>Algorithm.iter_comap.{u_1, u_2} {α : Type u_1} {β : Type u_2} [MeasurableSpace α] [TopologicalSpace α]\n  [OpensMeasurableSpace α] [MeasurableSpace β] [TopologicalSpace β] [BorelSpace β] (A : Algorithm α β) {f : α → β}\n  (hf : Continuous f) {n : ℕ} : Kernel (iter α n) α</code><span class=\"sep\"></span><code class=\"docstring\">Given a continuous function `f : α → β` representing the evaluation (e.g., objective function),\nthis constructs a new kernel that maps a history of points (in `iter α n`)\nto a probability distribution over the next point in `α`.\n\nThe original algorithm `A` provides a transition kernel `A.kernel_iter n` that depends on\nboth the previously proposed points and their corresponding evaluations.\nHowever, in practice, the algorithm itself only generates the sequence of points,\nand the evaluations are computed externally by applying `f` to each point.\n\nThe function `prod_eval n f` deterministically reconstructs the full history\n(points and their evaluations) from the point sequence alone, using `f` and\nthe `comap` pulls back the original kernel along this map,\nresulting in a kernel that operates directly on the sequence of points. </code>",
 "169":
 "<code>congrArg.{u, v} {α : Sort u} {β : Sort v} {a₁ a₂ : α} (f : α → β) (h : a₁ = a₂) : f a₁ = f a₂</code><span class=\"sep\"></span><code class=\"docstring\">Congruence in the function argument: if `a₁ = a₂` then `f a₁ = f a₂` for\nany (nondependent) function `f`. This is more powerful than it might look at first, because\nyou can also use a lambda expression for `f` to prove that\n`&lt;something containing a₁&gt; = &lt;something containing a₂&gt;`. This function is used\ninternally by tactics like `congr` and `simp` to apply equalities inside\nsubterms.\n\nFor more information: [Equality](https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#equality)\n</code>",
 "168":
 "<code>id.{u} {α : Sort u} (a : α) : α</code><span class=\"sep\"></span><code class=\"docstring\">The identity function. `id` takes an implicit argument `α : Sort u`\n(a type in any universe), and an argument `a : α`, and returns `a`.\n\nAlthough this may look like a useless function, one application of the identity\nfunction is to explicitly put a type on an expression. If `e` has type `T`,\nand `T'` is definitionally equal to `T`, then `@id T' e` typechecks, and Lean\nknows that this expression has type `T'` rather than `T`. This can make a\ndifference for typeclass inference, since `T` and `T'` may have different\ntypeclass instances on them. `show T' from e` is sugar for an `@id T' e`\nexpression.\n</code>",
 "167":
 "<code>Eq.mpr.{u} {α β : Sort u} (h : α = β) (b : β) : α</code><span class=\"sep\"></span><code class=\"docstring\">If `h : α = β` is a proof of type equality, then `h.mpr : β → α` is the induced\n\"cast\" operation in the reverse direction, mapping elements of `β` to elements of `α`.\n\nYou can prove theorems about the resulting element by induction on `h`, since\n`rfl.mpr` is definitionally the identity function.\n</code>",
 "166": "<code>fmax ⋯ ≤ fmax hf</code>",
 "165":
 "<code>Lipschitz.f_tilde_apply_out.{u_1} {α : Type u_1} [NormedAddCommGroup α] [CompactSpace α] [Nonempty α] {f : α → ℝ}\n  (hf : Lipschitz f) (c : α) {ε : ℝ} {x : α} (hx : x ∉ ball c (ε / 2)) : hf.f_tilde c ε x = f x</code>",
 "164":
 "<code class=\"docstring\">The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or\nnon-dependent hypotheses. It has many variants:\n- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.\n- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged\n  with the attribute `[simp]` and the given `hᵢ`'s, where the `hᵢ`'s are expressions.-\n- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated\n  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.\n- `simp [*]` simplifies the main goal target using the lemmas tagged with the\n  attribute `[simp]` and all hypotheses.\n- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.\n- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged\n  with the attribute `[simp]`, but removes the ones named `idᵢ`.\n- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If\n  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis\n  `hᵢ` is introduced, but the old one remains in the local context.\n- `simp at *` simplifies all the hypotheses and the target.\n- `simp [*] at *` simplifies target and all (propositional) hypotheses using the\n  other hypotheses.\n</code>",
 "163":
 "<code class=\"docstring\">The `have` tactic is for adding hypotheses to the local context of the main goal.\n* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.\n* `have h := e` uses the type of `e` for `t`.\n* `have : t := e` and `have := e` use `this` for the name of the hypothesis.\n* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,\n  where `_` stands for the tactics that follow this one.\n  It is convenient for types that have only one applicable constructor.\n  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the\n  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.\n</code>",
 "162":
 "<code>False : Prop</code><span class=\"sep\"></span><code class=\"docstring\">`False` is the empty proposition. Thus, it has no introduction rules.\nIt represents a contradiction. `False` elimination rule, `False.rec`,\nexpresses the fact that anything follows from a contradiction.\nThis rule is sometimes called ex falso (short for ex falso sequitur quodlibet),\nor the principle of explosion.\nFor more information: [Propositional Logic](https://lean-lang.org/theorem_proving_in_lean4/propositions_and_proofs.html#propositional-logic)\n</code>",
 "161": "<code>x' ∉ ball c (ε / 2)</code>",
 "160":
 "<code class=\"docstring\">`by_contra h` proves `⊢ p` by contradiction,\nintroducing a hypothesis `h : ¬p` and proving `False`.\n* If `p` is a negation `¬q`, `h : q` will be introduced instead of `¬¬q`.\n* If `p` is decidable, it uses `Decidable.byContradiction` instead of `Classical.byContradiction`.\n* If `h` is omitted, the introduced variable `_: ¬p` will be anonymous.\n</code>",
 "16": "<code>(n : ℕ) → Kernel (prod_iter_image α β n) α</code>",
 "159":
 "<code>Lipschitz.max_f_tilde_in_ball.{u_1} {α : Type u_1} [NormedAddCommGroup α] [NormedSpace ℝ α] [CompactSpace α]\n  [Nonempty α] {f : α → ℝ} (hf : Lipschitz f) (c : α) {ε : ℝ} (ε_pos : 0 &lt; ε) : compact_argmax ⋯ ∈ ball c (ε / 2)</code>",
 "158":
 "<code>compact_argmax_apply.{u_1, u_2} {α : Type u_1} {β : Type u_2} [TopologicalSpace α] [Nonempty α] [CompactSpace α]\n  [TopologicalSpace β] [LinearOrder β] {f : α → β} [ClosedIciTopology β] (hf : Continuous f) (y : α) :\n  f y ≤ f (compact_argmax hf)</code>",
 "157":
 "<code>lt_of_le_of_lt'.{u_1} {α : Type u_1} [Preorder α] {a b c : α} : b ≤ a → c &lt; b → c &lt; a</code>",
 "156": "<code>fmax hf &lt; hf.f_tilde c ε c</code>",
 "155":
 "<code>Lipschitz.max_f_lt_max_f_tilde.{u_1} {α : Type u_1} [NormedAddCommGroup α] [NormedSpace ℝ α] [CompactSpace α]\n  [Nonempty α] {f : α → ℝ} (hf : Lipschitz f) (c : α) {ε : ℝ} (ε_pos : 0 &lt; ε) : fmax hf &lt; fmax ⋯</code>",
 "154":
 "<code>Lipschitz.max_f_lt_f_tilde_c.{u_1} {α : Type u_1} [NormedAddCommGroup α] [CompactSpace α] [Nonempty α] {f : α → ℝ}\n  (hf : Lipschitz f) (c : α) {ε : ℝ} (ε_pos : 0 &lt; ε) : fmax hf &lt; hf.f_tilde c ε c</code>",
 "153":
 "<code>Lipschitz.dist_left.{u_1} {α : Type u_1} [PseudoMetricSpace α] (y : α) : Lipschitz fun x =&gt; dist x y</code>",
 "152":
 "<code>Lipschitz.div_const.{u_1} {α : Type u_1} [PseudoEMetricSpace α] {f : α → ℝ} (hf : Lipschitz f) {b : ℝ} :\n  Lipschitz fun a =&gt; f a / b</code>",
 "151":
 "<code>lipschitz_const.{u_1, u_2} {α : Type u_1} {β : Type u_2} [PseudoEMetricSpace β] [PseudoEMetricSpace α] {b : β} :\n  Lipschitz fun x =&gt; b</code>",
 "150":
 "<code>Lipschitz.sub.{u_1, u_2} {α : Type u_1} {β : Type u_2} [PseudoEMetricSpace α] {f g : α → β} [SeminormedAddCommGroup β]\n  (hf : Lipschitz f) (hg : Lipschitz g) : Lipschitz (f - g)</code>",
 "15":
 "<code>ProbabilityTheory.IsMarkovKernel.{u_1, u_2} {α : Type u_1} {β : Type u_2} {mα : MeasurableSpace α}\n  {mβ : MeasurableSpace β} (κ : Kernel α β) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">A kernel is a Markov kernel if every measure in its image is a probability measure. </code>",
 "149":
 "<code>Lipschitz.mul_const.{u_1} {α : Type u_1} [PseudoEMetricSpace α] {f : α → ℝ} (hf : Lipschitz f) {b : ℝ} :\n  Lipschitz fun a =&gt; f a * b</code>",
 "148":
 "<code>Lipschitz.const_mul.{u_1} {α : Type u_1} [PseudoEMetricSpace α] {f : α → ℝ} (hf : Lipschitz f) {b : ℝ} :\n  Lipschitz fun a =&gt; b * f a</code>",
 "147": "<code>Ne.symm.{u} {α : Sort u} {a b : α} (h : a ≠ b) : b ≠ a</code>",
 "146":
 "<code>half_pos.{u_2} {α : Type u_2} [Semifield α] [LinearOrder α] [IsStrictOrderedRing α] {a : α} (h : 0 &lt; a) : 0 &lt; a / 2</code>",
 "145":
 "<code>ne_of_lt.{u_1} {α : Type u_1} [Preorder α] {a b : α} (h : a &lt; b) : a ≠ b</code>",
 "144":
 "<code>CommGroupWithZero.mul_inv_cancel.{u_2} {G₀ : Type u_2} [self : CommGroupWithZero G₀] (a : G₀) : a ≠ 0 → a * a⁻¹ = 1</code><span class=\"sep\"></span><code class=\"docstring\">Every nonzero element of a group with zero is invertible. </code>",
 "143":
 "<code class=\"docstring\">Tactic for evaluating expressions in *commutative* (semi)rings, allowing for variables in the\nexponent. If the goal is not appropriate for `ring` (e.g. not an equality) `ring_nf` will be\nsuggested.\n\n* `ring!` will use a more aggressive reducibility setting to determine equality of atoms.\n* `ring1` fails if the target is not an equality.\n\nFor example:\n```\nexample (n : ℕ) (m : ℤ) : 2^(n+1) * m = 2 * 2^n * m := by ring\nexample (a b : ℤ) (n : ℕ) : (a + b)^(n + 2) = (a^2 + b^2 + a * b + b * a) * (a + b)^n := by ring\nexample (x y : ℕ) : x + id y = y + id x := by ring!\nexample (x : ℕ) (h : x * 2 &gt; 5): x + x &gt; 5 := by ring; assumption -- suggests ring_nf\n```\n</code>",
 "142": "<code>ε / 2 / (ε / 2) = 1</code>",
 "141":
 "<code class=\"docstring\">Given a main goal `ctx ⊢ t`, `suffices h : t' from e` replaces the main goal with `ctx ⊢ t'`,\n`e` must have type `t` in the context `ctx, h : t'`.\n\nThe variant `suffices h : t' by tac` is a shorthand for `suffices h : t' from by tac`.\nIf `h :` is omitted, the name `this` is used.\n </code>",
 "140": "<code>a ∈ sphere c (ε / 2)</code>",
 "14":
 "<code>Algorithm.markov_kernel.{u_1, u_2} {α : Type u_1} {β : Type u_2} [MeasurableSpace α] [MeasurableSpace β]\n  (self : Algorithm α β) (n : ℕ) : IsMarkovKernel (self.kernel_iter n)</code>",
 "139":
 "<code class=\"docstring\">Introduces one or more hypotheses, optionally naming and/or pattern-matching them.\nFor each hypothesis to be introduced, the remaining main goal's target type must\nbe a `let` or function type.\n\n* `intro` by itself introduces one anonymous hypothesis, which can be accessed\n  by e.g. `assumption`.\n* `intro x y` introduces two hypotheses and names them. Individual hypotheses\n  can be anonymized via `_`, or matched against a pattern:\n  ```lean\n  -- ... ⊢ α × β → ...\n  intro (a, b)\n  -- ..., a : α, b : β ⊢ ...\n  ```\n* Alternatively, `intro` can be combined with pattern matching much like `fun`:\n  ```lean\n  intro\n  | n + 1, 0 =&gt; tac\n  | ...\n  ```\n</code>",
 "138":
 "<code>HSub.hSub.{u, v, w} {α : Type u} {β : Type v} {γ : outParam (Type w)} [self : HSub α β γ] : α → β → γ</code><span class=\"sep\"></span><code class=\"docstring\">`a - b` computes the difference of `a` and `b`.\nThe meaning of this notation is type-dependent.\n* For natural numbers, this operator saturates at 0: `a - b = 0` when `a ≤ b`. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `-` in identifiers is `sub` (when used as a binary operator).</code>",
 "137":
 "<code>HMul.hMul.{u, v, w} {α : Type u} {β : Type v} {γ : outParam (Type w)} [self : HMul α β γ] : α → β → γ</code><span class=\"sep\"></span><code class=\"docstring\">`a * b` computes the product of `a` and `b`.\nThe meaning of this notation is type-dependent. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `*` in identifiers is `mul`.</code>",
 "136":
 "<code>HDiv.hDiv.{u, v, w} {α : Type u} {β : Type v} {γ : outParam (Type w)} [self : HDiv α β γ] : α → β → γ</code><span class=\"sep\"></span><code class=\"docstring\">`a / b` computes the result of dividing `a` by `b`.\nThe meaning of this notation is type-dependent.\n* For most types like `Nat`, `Int`, `Rat`, `Real`, `a / 0` is defined to be `0`.\n* For `Nat`, `a / b` rounds downwards.\n* For `Int`, `a / b` rounds downwards if `b` is positive or upwards if `b` is negative.\n  It is implemented as `Int.ediv`, the unique function satisfying\n  `a % b + b * (a / b) = a` and `0 ≤ a % b &lt; natAbs b` for `b ≠ 0`.\n  Other rounding conventions are available using the functions\n  `Int.fdiv` (floor rounding) and `Int.tdiv` (truncation rounding).\n* For `Float`, `a / 0` follows the IEEE 754 semantics for division,\n  usually resulting in `inf` or `nan`. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `/` in identifiers is `div`.</code>",
 "135":
 "<code>Metric.sphere.{u} {α : Type u} [PseudoMetricSpace α] (x : α) (ε : ℝ) : Set α</code><span class=\"sep\"></span><code class=\"docstring\">`sphere x ε` is the set of all points `y` with `dist y x = ε` </code>",
 "134":
 "<code>Lipschitz.if.{u_1} {α : Type u_1} [NormedAddCommGroup α] [NormedSpace ℝ α] {f g : α → ℝ} {c : α} {ε : ℝ}\n  [(a : α) → Decidable (a ∈ ball c ε)] (hp : ∀ a ∈ sphere c ε, g a = 0) (hf : Lipschitz f) (hg : Lipschitz g) :\n  Lipschitz fun a =&gt; if a ∈ ball c ε then f a + g a else f a</code>",
 "133":
 "<code>LT.lt.{u} {α : Type u} [self : LT α] : α → α → Prop</code><span class=\"sep\"></span><code class=\"docstring\">The less-than relation: `x &lt; y` \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `&lt;` in identifiers is `lt`.</code>",
 "132": "<code>0 &lt; ε</code>",
 "131":
 "<code>Lipschitz.f_tilde_lipschitz.{u_1} {α : Type u_1} [NormedAddCommGroup α] [NormedSpace ℝ α] [CompactSpace α] [Nonempty α]\n  {f : α → ℝ} (hf : Lipschitz f) (c : α) {ε : ℝ} (ε_pos : 0 &lt; ε) : Lipschitz (hf.f_tilde c ε)</code>",
 "130":
 "<code>fmin.{u_1, u_2} {α : Type u_1} [PseudoMetricSpace α] [CompactSpace α] [Nonempty α] {β : Type u_2} [PseudoMetricSpace β]\n  [LinearOrder β] [ClosedIicTopology β] {f : α → β} (hf : Lipschitz f) : β</code><span class=\"sep\"></span><code class=\"docstring\">The minimum of a Lipschitz function over `α`. </code>",
 "13":
 "<code>prod_iter_image.{u_1, u_2} (α : Type u_1) (β : Type u_2) (n : ℕ) : Type (max u_1 u_2)</code><span class=\"sep\"></span><code class=\"docstring\">`prod_iter_image α β n` is the input space of the algorithm at iteration `n`.\n\nIt consists of:\n- a sequence of `n + 1` past points in `α`,\n- and their corresponding evaluations in `β`.\n\nThis pair encodes the full information available up to iteration `n`. </code>",
 "129":
 "<code>Metric.ball.{u} {α : Type u} [PseudoMetricSpace α] (x : α) (ε : ℝ) : Set α</code><span class=\"sep\"></span><code class=\"docstring\">`ball x ε` is the set of all points `y` with `dist y x &lt; ε` </code>",
 "128":
 "<code class=\"docstring\">`if c then t else e` is notation for `ite c t e`, \"if-then-else\", which decides to\nreturn `t` or `e` depending on whether `c` is true or false. The explicit argument\n`c : Prop` does not have any actual computational content, but there is an additional\n`[Decidable c]` argument synthesized by typeclass inference which actually\ndetermines how to evaluate `c` to true or false. Write `if h : c then t else e`\ninstead for a \"dependent if-then-else\" `dite`, which allows `t`/`e` to use the fact\nthat `c` is true/false.\n</code>",
 "127":
 "<code>Lipschitz.f_tilde.{u_1} {α : Type u_1} [NormedAddCommGroup α] [CompactSpace α] [Nonempty α] {f : α → ℝ}\n  (hf : Lipschitz f) (c : α) (ε : ℝ) (x : α) : ℝ</code><span class=\"sep\"></span><code class=\"docstring\">Given a `Lipschitz` function `f` over a `CompactSpace α`, construct a `Lipschitz`\nfunction (see `Lipschitz.f_tilde_lipschitz`) that is indistinguishable from `f` outside\nof a ball of radius `ε` such that the maximum of this new function is greater than the\nmaximum of `f` and is located in the ball. </code>",
 "126":
 "<code>Iff (a b : Prop) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">If and only if, or logical bi-implication. `a ↔ b` means that `a` implies `b` and vice versa.\nBy `propext`, this implies that `a` and `b` are equal and hence any expression involving `a`\nis equivalent to the corresponding expression with `b` instead.\n\n\nConventions for notations in identifiers:\n\n * The recommended spelling of `↔` in identifiers is `iff`.\n\n * The recommended spelling of `&lt;-&gt;` in identifiers is `iff` (prefer `↔` over `&lt;-&gt;`).</code>",
 "125":
 "<code>Nonempty.{u} (α : Sort u) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">`Nonempty α` is a typeclass that says that `α` is not an empty type,\nthat is, there exists an element in the type. It differs from `Inhabited α`\nin that `Nonempty α` is a `Prop`, which means that it does not actually carry\nan element of `α`, only a proof that *there exists* such an element.\nGiven `Nonempty α`, you can construct an element of `α` *nonconstructively*\nusing `Classical.choice`.\n</code>",
 "124": "<code>Nonempty α</code>",
 "123":
 "<code>CompactSpace.{u_1} (X : Type u_1) [TopologicalSpace X] : Prop</code><span class=\"sep\"></span><code class=\"docstring\">Type class for compact spaces. Separation is sometimes included in the definition, especially\nin the French literature, but we do not include it here. </code>",
 "122": "<code>CompactSpace α</code>",
 "121":
 "<code>Real : Type</code><span class=\"sep\"></span><code class=\"docstring\">The type `ℝ` of real numbers constructed as equivalence classes of Cauchy sequences of rational\nnumbers. </code>",
 "120":
 "<code>NormedSpace.{u_6, u_7} (𝕜 : Type u_6) (E : Type u_7) [NormedField 𝕜] [SeminormedAddCommGroup E] : Type (max u_6 u_7)</code><span class=\"sep\"></span><code class=\"docstring\">A normed space over a normed field is a vector space endowed with a norm which satisfies the\nequality `‖c • x‖ = ‖c‖ ‖x‖`. We require only `‖c • x‖ ≤ ‖c‖ ‖x‖` in the definition, then prove\n`‖c • x‖ = ‖c‖ ‖x‖` in `norm_smul`.\n\nNote that since this requires `SeminormedAddCommGroup` and not `NormedAddCommGroup`, this\ntypeclass can be used for \"semi normed spaces\" too, just as `Module` can be used for\n\"semi modules\". </code>",
 "12":
 "<code>ProbabilityTheory.Kernel.{u_1, u_2} (α : Type u_1) (β : Type u_2) [MeasurableSpace α] [MeasurableSpace β] :\n  Type (max u_1 u_2)</code><span class=\"sep\"></span><code class=\"docstring\">A kernel from a measurable space `α` to another measurable space `β` is a measurable function\n`κ : α → Measure β`. The measurable space structure on `MeasureTheory.Measure β` is given by\n`MeasureTheory.Measure.instMeasurableSpace`. A map `κ : α → MeasureTheory.Measure β` is measurable\niff `∀ s : Set β, MeasurableSet s → Measurable (fun a ↦ κ a s)`. </code>",
 "119": "<code>NormedSpace ℝ α</code>",
 "118":
 "<code>NormedAddCommGroup.{u_8} (E : Type u_8) : Type u_8</code><span class=\"sep\"></span><code class=\"docstring\">A normed group is an additive group endowed with a norm for which `dist x y = ‖x - y‖` defines a\nmetric space structure. </code>",
 "117": "<code>NormedAddCommGroup α</code>",
 "116": "<code>α → ℝ</code>",
 "115": "<code>Algorithm α ℝ</code>",
 "114":
 "<code>sample_iff_consistent.{u_1} {α : Type u_1} [MeasurableSpace α] [NormedAddCommGroup α] [NormedSpace ℝ α] [CompactSpace α]\n  [Nonempty α] [OpensMeasurableSpace α] (A : Algorithm α ℝ) :\n  (∀ ⦃f : α → ℝ⦄ (hf : Lipschitz f), sample_whole_space A ⋯) ↔\n    ∀ ⦃f : α → ℝ⦄ (hf : Lipschitz f), is_consistent_over_Lipschitz A hf</code>",
 "113":
 "<code>is_consistent_over_Lipschitz.{u_1, u_2} {α : Type u_1} [PseudoMetricSpace α] [CompactSpace α] [Nonempty α]\n  {β : Type u_2} [Nonempty β] [PseudoMetricSpace β] [LinearOrder β] [ClosedIciTopology β] [MeasurableSpace α]\n  [MeasurableSpace β] [OpensMeasurableSpace α] [BorelSpace β] (A : Algorithm α β) {f : α → β} (hf : Lipschitz f) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">An algorithm `A` is consistent over all Lipschitz functions. </code>",
 "112":
 "<code>sample_whole_space.{u_1, u_2} {α : Type u_1} [PseudoMetricSpace α] [CompactSpace α] [Nonempty α] {β : Type u_2}\n  [PseudoMetricSpace β] [MeasurableSpace α] [MeasurableSpace β] [OpensMeasurableSpace α] [BorelSpace β]\n  (A : Algorithm α β) {f : α → β} (hf : Continuous f) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">**Main definition**: Given a function `f`, an algorithm `A` sample the whole space\nif `∀ ε &gt; 0, lim_(n → ∞) A.measure f n {u | max_min_dist u &gt; ε} = 0`. </code>",
 "111":
 "<code>min_dist_x_continuous.{u_1} {α : Type u_1} [PseudoMetricSpace α] {n : ℕ} (u : iter α n) : Continuous (min_dist_x u)</code><span class=\"sep\"></span><code class=\"docstring\">For any `(u : iter α n)`, `min_dist_x u` is continuous </code>",
 "110":
 "<code>compact_argmax.{u_1, u_2} {α : Type u_1} {β : Type u_2} [TopologicalSpace α] [Nonempty α] [CompactSpace α]\n  [TopologicalSpace β] [LinearOrder β] {f : α → β} [ClosedIciTopology β] (hf : Continuous f) : α</code>",
 "11": "<code>ℕ</code>",
 "109":
 "<code>max_min_dist.{u_1} {α : Type u_1} [PseudoMetricSpace α] [CompactSpace α] [Nonempty α] {n : ℕ} (u : iter α n) : ℝ</code><span class=\"sep\"></span><code class=\"docstring\">Given a sequence `u`, maximum over `α` of `min_dist_x u`: the maximum distance between\nany element in `α` and `u`. </code>",
 "108":
 "<code>Tuple.min.{u_1} {α : Type u_1} [LinearOrder α] [Nonempty α] {n : ℕ} (f : Fin n → α) : α</code>",
 "107":
 "<code>min_dist_x.{u_1} {α : Type u_1} [PseudoMetricSpace α] {n : ℕ} (u : iter α n) (x : α) : ℝ</code><span class=\"sep\"></span><code class=\"docstring\">Given a sequence `u` and a element `x`, returns `min_(0 ≤ i &lt; n) dist (u i) x. </code>",
 "106": "<code>ENNReal</code>",
 "105":
 "<code>Filter.atTop.{u_3} {α : Type u_3} [Preorder α] : Filter α</code><span class=\"sep\"></span><code class=\"docstring\">`atTop` is the filter representing the limit `→ ∞` on an ordered set.\nIt is generated by the collection of up-sets `{b | a ≤ b}`.\n(The preorder need not have a top element for this to be well defined,\nand indeed is trivial when a top element exists.) </code>",
 "104":
 "<code>Filter.Tendsto.{u_1, u_2} {α : Type u_1} {β : Type u_2} (f : α → β) (l₁ : Filter α) (l₂ : Filter β) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">`Filter.Tendsto` is the generic \"limit of a function\" predicate.\n`Tendsto f l₁ l₂` asserts that for every `l₂` neighborhood `a`,\nthe `f`-preimage of `a` is an `l₁` neighborhood. </code>",
 "103":
 "<code>is_consistent.{u_1, u_2} {α : Type u_1} [PseudoMetricSpace α] [CompactSpace α] [Nonempty α] {β : Type u_2} [Nonempty β]\n  [PseudoMetricSpace β] [LinearOrder β] [ClosedIciTopology β] [MeasurableSpace α] [MeasurableSpace β]\n  [OpensMeasurableSpace α] [BorelSpace β] (A : Algorithm α β) {f : α → β} (hf : Lipschitz f) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">**Main definition**: An algorithm `A` is consistent over a Lipschitz function `f`\nif for any `ε &gt; 0`, `lim_(n → ∞) measure_dist_max n = 0`. </code>",
 "102":
 "<code>Lipschitz.continuous.{u_1, u_2} {α : Type u_1} {β : Type u_2} [PseudoEMetricSpace α] {f : α → β} [PseudoEMetricSpace β]\n  (hf : Lipschitz f) : Continuous f</code>",
 "101":
 "<code>measure_dist_max.{u_1, u_2} {α : Type u_1} [PseudoMetricSpace α] [CompactSpace α] [Nonempty α] {β : Type u_2}\n  [Nonempty β] [PseudoMetricSpace β] [LinearOrder β] [ClosedIciTopology β] [MeasurableSpace α] [MeasurableSpace β]\n  [OpensMeasurableSpace α] [BorelSpace β] (A : Algorithm α β) {f : α → β} (hf : Lipschitz f) (ε : ℝ) (n : ℕ) : ENNReal</code><span class=\"sep\"></span><code class=\"docstring\">Given an algorithm `A`, the function that, given `ε` and `n`, returns\nthe measure of the set of sequences of size `n + 1` such that the maximum of\n`f` over these sequences is at least `ε` away from from `fmax`. </code>",
 "100":
 "<code>Tuple.max.{u_1} {α : Type u_1} [LinearOrder α] [Nonempty α] {n : ℕ} (f : Fin n → α) : α</code>",
 "10":
 "<code>Algorithm.kernel_iter.{u_1, u_2} {α : Type u_1} {β : Type u_2} [MeasurableSpace α] [MeasurableSpace β]\n  (self : Algorithm α β) (n : ℕ) : Kernel (prod_iter_image α β n) α</code>",
 "1": "<code>Type u_1</code>",
 "0":
 "<code>Algorithm.{u_1, u_2} (α : Type u_1) (β : Type u_2) [MeasurableSpace α] [MeasurableSpace β] : Type (max u_1 u_2)</code><span class=\"sep\"></span><code class=\"docstring\">`Algorithm α β` represents a general iterative stochastic optimization algorithm.\n\nIt models a sequence of updates where:\n- `α` is the search space (e.g., parameters, candidate solutions),\n- `β` is the evaluation space (e.g., objective values, feedback),\n- `ν` is the initial probability measure over `α` (the starting distribution of candidates),\n- `kernel_iter n` is a Markov kernel that outputs a new candidate in `α`\n  given the history of the first `n` points and their evaluations,\n  i.e., from the space `prod_iter_image α β n` = (`α × β`)ⁿ,\n- `markov_kernel n` asserts that each such `kernel_iter n` is a valid Markov kernel.\n\nIt allows formal reasoning over joint distributions of evaluated points and convergence\nproperties. </code>"}