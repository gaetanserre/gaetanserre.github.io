{"99": "<code>Algorithm α ℝ</code>",
 "98":
 "<code>sample_iff_consistent.{u_1} {α : Type u_1} [MeasurableSpace α] [NormedAddCommGroup α] [NormedSpace ℝ α] [CompactSpace α]\n  [Nonempty α] [OpensMeasurableSpace α] (A : Algorithm α ℝ) :\n  (∀ ⦃f : α → ℝ⦄ (hf : Lipschitz f), sample_whole_space A ⋯) ↔ ∀ ⦃f : α → ℝ⦄ (hf : Lipschitz f), is_consistent A hf</code>",
 "97":
 "<code>sample_whole_space.{u_1, u_2} {α : Type u_1} [PseudoMetricSpace α] {β : Type u_2} [CompactSpace α] [Nonempty α]\n  [MeasurableSpace α] [MeasurableSpace β] [PseudoMetricSpace β] [OpensMeasurableSpace α] [BorelSpace β]\n  (A : Algorithm α β) {f : α → β} (hf : Continuous f) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">**Main definition**: Given a function `f`, an algorithm `A` sample the whole space\nif `∀ ε &gt; 0, lim_(n → ∞) A.measure f n {u | max_min_dist u &gt; ε} = 0`. </code>",
 "96":
 "<code>min_dist_x_continuous.{u_1} {α : Type u_1} [PseudoMetricSpace α] {n : ℕ} (u : iter α n) : Continuous (min_dist_x u)</code><span class=\"sep\"></span><code class=\"docstring\">For any `(u : iter α n)`, `min_dist_x u` is continuous </code>",
 "95":
 "<code>compact_argmax.{u_1, u_2} {α : Type u_1} {β : Type u_2} [TopologicalSpace α] [Nonempty α] [CompactSpace α]\n  [TopologicalSpace β] [LinearOrder β] {f : α → β} [ClosedIciTopology β] (hf : Continuous f) : α</code>",
 "94":
 "<code>max_min_dist.{u_1} {α : Type u_1} [PseudoMetricSpace α] [CompactSpace α] [Nonempty α] {n : ℕ} (u : iter α n) : ℝ</code><span class=\"sep\"></span><code class=\"docstring\">Given a sequence `u`, maximum over `α` of `min_dist_x u`: the maximum distance between\nany element in `α` and `u`. </code>",
 "93":
 "<code>Tuple.min.{u_1} {α : Type u_1} [LinearOrder α] [Nonempty α] {n : ℕ} (f : iter α n) : α</code>",
 "92": "<code>α</code>",
 "91":
 "<code>min_dist_x.{u_1} {α : Type u_1} [PseudoMetricSpace α] {n : ℕ} (u : iter α n) (x : α) : ℝ</code><span class=\"sep\"></span><code class=\"docstring\">Given a sequence `u` and a element `x`, returns `min_(0 ≤ i &lt; n) dist (u i) x. </code>",
 "90": "<code>ENNReal</code>",
 "9": "<code>Measure α</code>",
 "89":
 "<code>Filter.atTop.{u_3} {α : Type u_3} [Preorder α] : Filter α</code><span class=\"sep\"></span><code class=\"docstring\">`atTop` is the filter representing the limit `→ ∞` on an ordered set.\nIt is generated by the collection of up-sets `{b | a ≤ b}`.\n(The preorder need not have a top element for this to be well defined,\nand indeed is trivial when a top element exists.) </code>",
 "88":
 "<code>Filter.Tendsto.{u_1, u_2} {α : Type u_1} {β : Type u_2} (f : α → β) (l₁ : Filter α) (l₂ : Filter β) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">`Filter.Tendsto` is the generic \"limit of a function\" predicate.\n`Tendsto f l₁ l₂` asserts that for every `l₂` neighborhood `a`,\nthe `f`-preimage of `a` is an `l₁` neighborhood. </code>",
 "87":
 "<code>is_consistent.{u_1, u_2} {α : Type u_1} [PseudoMetricSpace α] {β : Type u_2} [CompactSpace α] [Nonempty α]\n  [PseudoMetricSpace β] [Nonempty β] [LinearOrder β] [ClosedIciTopology β] [MeasurableSpace α] [MeasurableSpace β]\n  [OpensMeasurableSpace α] [BorelSpace β] (A : Algorithm α β) {f : α → β} (hf : Lipschitz f) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">**Main definition**: An algorithm `A` is consistent over a Lipschitz function `f`\nif for any `ε &gt; 0`, `lim_(n → ∞) measure_dist_max n = 0`. </code>",
 "86":
 "<code>Lipschitz.continuous.{u_1, u_2} {α : Type u_1} {β : Type u_2} [PseudoEMetricSpace α] {f : α → β} [PseudoEMetricSpace β]\n  (hf : Lipschitz f) : Continuous f</code>",
 "85":
 "<code>measure_dist_max.{u_1, u_2} {α : Type u_1} [PseudoMetricSpace α] {β : Type u_2} [CompactSpace α] [Nonempty α]\n  [PseudoMetricSpace β] [Nonempty β] [LinearOrder β] [ClosedIciTopology β] [MeasurableSpace α] [MeasurableSpace β]\n  [OpensMeasurableSpace α] [BorelSpace β] (A : Algorithm α β) {f : α → β} (hf : Lipschitz f) (ε : ℝ) (n : ℕ) : ENNReal</code><span class=\"sep\"></span><code class=\"docstring\">Given an algorithm `A`, the function that, given `ε` and `n`, returns\nthe measure of the set of sequences of size `n + 1` such that the maximum of\n`f` over these sequences is at least `ε` away from from `fmax`. </code>",
 "84":
 "<code>Tuple.max.{u_1} {α : Type u_1} [LinearOrder α] [Nonempty α] {n : ℕ} (f : iter α n) : α</code>",
 "83":
 "<code>Dist.dist.{u_3} {α : Type u_3} [self : Dist α] : α → α → ℝ</code><span class=\"sep\"></span><code class=\"docstring\">Distance between two points </code>",
 "82": "<code>iter α n</code>",
 "81": "<code>ℝ</code>",
 "80":
 "<code>Lipschitz.{u_1, u_2} {α : Type u_1} {β : Type u_2} [PseudoEMetricSpace α] [PseudoEMetricSpace β] (f : α → β) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">A wrapper around `LipschitzWith` of Mathlib. A function is `Lipschitz` if it exists\na `K : ℝ≥0` such that `LipschitzWith K f`. </code>",
 "8":
 "<code>MeasureTheory.IsProbabilityMeasure.{u_1} {α : Type u_1} {m0 : MeasurableSpace α} (μ : Measure α) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">A measure `μ` is called a probability measure if `μ univ = 1`. </code>",
 "79": "<code>Lipschitz f</code>",
 "78":
 "<code>set_dist_max.{u_1, u_2} {α : Type u_1} [PseudoMetricSpace α] {β : Type u_2} [CompactSpace α] [Nonempty α]\n  [PseudoMetricSpace β] [Nonempty β] [LinearOrder β] [ClosedIciTopology β] {f : α → β} (hf : Lipschitz f) {n : ℕ}\n  (ε : ℝ) : Set (iter α n)</code><span class=\"sep\"></span><code class=\"docstring\">The set of sequences of size `n + 1` such that the maximum of `f` over\nthese sequences is at least `ε` away from from `fmax`. </code>",
 "77":
 "<code>fmax.{u_1, u_2} {α : Type u_1} [PseudoMetricSpace α] {β : Type u_2} [CompactSpace α] [Nonempty α] [PseudoMetricSpace β]\n  [LinearOrder β] [ClosedIciTopology β] {f : α → β} (hf : Lipschitz f) : β</code><span class=\"sep\"></span><code class=\"docstring\">The maximum of a Lipschitz function over `α`. </code>",
 "76":
 "<code>Algorithm.fin_measure.{u_1, u_2} {α : Type u_1} {β : Type u_2} [MeasurableSpace α] [TopologicalSpace α]\n  [OpensMeasurableSpace α] [MeasurableSpace β] [TopologicalSpace β] [BorelSpace β] (A : Algorithm α β) {f : α → β}\n  (hf : Continuous f) {n : ℕ} : MeasureTheory.Measure (iter α n)</code><span class=\"sep\"></span><code class=\"docstring\">The measure on finite sequences of iterations, defined by pushing forward `measure`\nalong the measurable function `frestrictLe n : (ℕ → α) → iter α n` that restricts\nthe infinite sequence to its first `n` elements. This is the measure that will be used\nthroughout the formalization. </code>",
 "75":
 "<code>Eq.{u_1} {α : Sort u_1} : α → α → Prop</code><span class=\"sep\"></span><code class=\"docstring\">The equality relation. It has one introduction rule, `Eq.refl`.\nWe use `a = b` as notation for `Eq a b`.\nA fundamental property of equality is that it is an equivalence relation.\n```\nvariable (α : Type) (a b c d : α)\nvariable (hab : a = b) (hcb : c = b) (hcd : c = d)\n\nexample : a = d :=\n  Eq.trans (Eq.trans hab (Eq.symm hcb)) hcd\n```\nEquality is much more than an equivalence relation, however. It has the important property that every assertion\nrespects the equivalence, in the sense that we can substitute equal expressions without changing the truth value.\nThat is, given `h1 : a = b` and `h2 : p a`, we can construct a proof for `p b` using substitution: `Eq.subst h1 h2`.\nExample:\n```\nexample (α : Type) (a b : α) (p : α → Prop)\n        (h1 : a = b) (h2 : p a) : p b :=\n  Eq.subst h1 h2\n\nexample (α : Type) (a b : α) (p : α → Prop)\n    (h1 : a = b) (h2 : p a) : p b :=\n  h1 ▸ h2\n```\nThe triangle in the second presentation is a macro built on top of `Eq.subst` and `Eq.symm`, and you can enter it by typing `\\t`.\nFor more information: [Equality](https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#equality)\n\n\nConventions for notations in identifiers:\n\n * The recommended spelling of `=` in identifiers is `eq`.</code>",
 "74": "<code>{ x // x ∈ Finset.Iic n }</code>",
 "73":
 "<code>Finset.Iic.{u_1} {α : Type u_1} [Preorder α] [LocallyFiniteOrderBot α] (b : α) : Finset α</code><span class=\"sep\"></span><code class=\"docstring\">The finset $(-∞, b]$ of elements `x` such that `x ≤ b`. Basically `Set.Iic b` as a finset. </code>",
 "72":
 "<code>Set.pi.{u_1, u_2} {ι : Type u_1} {α : ι → Type u_2} (s : Set ι) (t : (i : ι) → Set (α i)) : Set ((i : ι) → α i)</code><span class=\"sep\"></span><code class=\"docstring\">Given an index set `ι` and a family of sets `t : Π i, Set (α i)`, `pi s t`\nis the set of dependent functions `f : Πa, π a` such that `f i` belongs to `t i`\nwhenever `i ∈ s`. </code>",
 "71":
 "<code>Set.univ.{u} {α : Type u} : Set α</code><span class=\"sep\"></span><code class=\"docstring\">The universal set on a type `α` is the set containing all elements of `α`.\n\nThis is conceptually the \"same as\" `α` (in set theory, it is actually the same), but type theory\nmakes the distinction that `α` is a type while `Set.univ` is a term of type `Set α`. `Set.univ` can\nitself be coerced to a type `↥Set.univ` which is in bijection with (but distinct from) `α`. </code>",
 "70":
 "<code>MeasureTheory.Measure.restrict.{u_2} {α : Type u_2} {_m0 : MeasurableSpace α} (μ : Measure α) (s : Set α) : Measure α</code><span class=\"sep\"></span><code class=\"docstring\">Restrict a measure `μ` to a set `s`. </code>",
 "7":
 "<code>Algorithm.prob_measure.{u_1, u_2} {α : Type u_1} {β : Type u_2} [MeasurableSpace α] [MeasurableSpace β]\n  (self : Algorithm α β) : IsProbabilityMeasure self.ν</code>",
 "69":
 "<code>Set.EqOn.{u, v} {α : Type u} {β : Type v} (f₁ f₂ : α → β) (s : Set α) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">Two functions `f₁ f₂ : α → β` are equal on `s` if `f₁ x = f₂ x` for all `x ∈ s`. </code>",
 "68": "<code>EqOn f g s</code>",
 "67": "<code>Set α</code>",
 "66": "<code>Continuous g</code>",
 "65":
 "<code>Algorithm.eq_restrict.{u_1, u_2} {α : Type u_1} {β : Type u_2} [MeasurableSpace α] [TopologicalSpace α]\n  [OpensMeasurableSpace α] [MeasurableSpace β] [TopologicalSpace β] [BorelSpace β] (A : Algorithm α β) {f g : α → β}\n  (hf : Continuous f) (hg : Continuous g) {s : Set α} (hs : MeasurableSet s) (h : EqOn f g s) (n : ℕ) :\n  (A.fin_measure hf).restrict (univ.pi fun x =&gt; s) = (A.fin_measure hg).restrict (univ.pi fun x =&gt; s)</code><span class=\"sep\"></span><code class=\"docstring\">If two continuous functions `f` and `g` agree on a measurable set `s`, then the algorithm's\ninduced measures at iteration `n` are identical when restricted to trajectories that stay\nwithin `s`. This establishes that the algorithm depends only on the objective function values\non the relevant domain. </code>",
 "64":
 "<code>Membership.mem.{u, v} {α : outParam (Type u)} {γ : Type v} [self : Membership α γ] : γ → α → Prop</code><span class=\"sep\"></span><code class=\"docstring\">The membership relation `a ∈ s : Prop` where `a : α`, `s : γ`. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `∈` in identifiers is `mem`.</code>",
 "63":
 "<code>setOf.{u} {α : Type u} (p : α → Prop) : Set α</code><span class=\"sep\"></span><code class=\"docstring\">Turn a predicate `p : α → Prop` into a set, also written as `{x | p x}` </code>",
 "62":
 "<code>HasSubset.Subset.{u} {α : Type u} [self : HasSubset α] : α → α → Prop</code><span class=\"sep\"></span><code class=\"docstring\">Subset relation: `a ⊆ b`  \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `⊆` in identifiers is `subset`.</code>",
 "61":
 "<code>LE.le.{u} {α : Type u} [self : LE α] : α → α → Prop</code><span class=\"sep\"></span><code class=\"docstring\">The less-equal relation: `x ≤ y` \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `≤` in identifiers is `le`.\n\n * The recommended spelling of `&lt;=` in identifiers is `le` (prefer `≤` over `&lt;=`).</code>",
 "60":
 "<code>Nat : Type</code><span class=\"sep\"></span><code class=\"docstring\">The natural numbers, starting at zero.\n\nThis type is special-cased by both the kernel and the compiler, and overridden with an efficient\nimplementation. Both use a fast arbitrary-precision arithmetic library (usually\n[GMP](https://gmplib.org/)); at runtime, `Nat` values that are sufficiently small are unboxed.\n</code>",
 "6":
 "<code>MeasureTheory.Measure.{u_6} (α : Type u_6) [MeasurableSpace α] : Type u_6</code><span class=\"sep\"></span><code class=\"docstring\">A measure is defined to be an outer measure that is countably additive on\nmeasurable sets, with the additional assumption that the outer measure is the canonical\nextension of the restricted measure.\n\nThe measure of a set `s`, denoted `μ s`, is an extended nonnegative real. The real-valued version\nis written `μ.real s`.\n</code>",
 "59":
 "<code>Tuple.subTuple.{u_1} {α : Type u_1} {n m : ℕ} (hnm : n ≤ m) (u : iter α m) : iter α n</code><span class=\"sep\"></span><code class=\"docstring\">Given `n ≤ m`, this is the restriction of a function `u : iter α m`\nto a function `iter α n`. </code>",
 "58": "<code>iter α m</code>",
 "57": "<code>e ⊆ {u | subTuple hmn u ∈ s}</code>",
 "56": "<code>n ≤ m</code>",
 "55": "<code>MeasurableSet e</code>",
 "54": "<code>Set (iter α m)</code>",
 "53":
 "<code>MeasurableSet.{u_1} {α : Type u_1} [MeasurableSpace α] (s : Set α) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">`MeasurableSet s` means that `s` is measurable (in the ambient measure space on `α`) </code>",
 "52": "<code>MeasurableSet s</code>",
 "51":
 "<code>Set.{u} (α : Type u) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">A set is a collection of elements of some type `α`.\n\nAlthough `Set` is defined as `α → Prop`, this is an implementation detail which should not be\nrelied on. Instead, `setOf` and membership of a set (`∈`) should be used to convert between sets\nand predicates.\n</code>",
 "50": "<code>Set (iter α n)</code>",
 "5":
 "<code>Algorithm.ν.{u_1, u_2} {α : Type u_1} {β : Type u_2} [MeasurableSpace α] [MeasurableSpace β] (self : Algorithm α β) :\n  Measure α</code>",
 "49":
 "<code>Algorithm.fin_measure_mono.{u_1, u_2} {α : Type u_1} {β : Type u_2} [MeasurableSpace α] [TopologicalSpace α]\n  [OpensMeasurableSpace α] [MeasurableSpace β] [TopologicalSpace β] [BorelSpace β] (A : Algorithm α β) {n m : ℕ}\n  {s : Set (iter α n)} (hs : MeasurableSet s) {e : Set (iter α m)} (he : MeasurableSet e) (hmn : n ≤ m)\n  (hse : e ⊆ {u | subTuple hmn u ∈ s}) {f : α → β} (hf : Continuous f) : (A.fin_measure hf) e ≤ (A.fin_measure hf) s</code><span class=\"sep\"></span><code class=\"docstring\">Monotonicity of the algorithm's induced measures under trajectory extension.\n\nLet `s : Set iter α n` be a measurable set of point sequences of length `n`,\nand `e : Set iter α m` for some `m ≥ n` a set of longer trajectories such that\nevery `u ∈ e` satisfies `subTuple hmn u ∈ s`.\n\nThen the measure assigned to `e` by the algorithm at step `m` is less than or equal to\nthe measure assigned to `s` at step `n`.\n\nThis expresses that the family of measures is projectively consistent:\nthe measure on longer trajectories contracts to the measure on shorter ones via truncation.\n\nFormally: if `e ⊆ {u | subTuple hmn u ∈ s}`, then `A.fin_measure hf m e ≤ A.fin_measure hf n s`. </code>",
 "48":
 "<code>Preorder.frestrictLe.{u_1, u_2} {α : Type u_1} [Preorder α] {π : α → Type u_2} [LocallyFiniteOrderBot α] (a : α)\n  (f : (i : α) → π i) (i : { x // x ∈ Finset.Iic a }) : π ↑i</code><span class=\"sep\"></span><code class=\"docstring\">Restrict domain of a function `f` indexed by `α` to elements `≤ a`, seen as a finite set. </code>",
 "47":
 "<code>ProbabilityTheory.Kernel.map.{u_1, u_2, u_4} {α : Type u_1} {β : Type u_2} {mα : MeasurableSpace α}\n  {mβ : MeasurableSpace β} {γ : Type u_4} [MeasurableSpace γ] (κ : Kernel α β) (f : β → γ) : Kernel α γ</code><span class=\"sep\"></span><code class=\"docstring\">The pushforward of a kernel along a function.\nIf the function is not measurable, we use zero instead. This choice of junk\nvalue ensures that typeclass inference can infer that the `map` of a kernel\nsatisfying `IsZeroOrMarkovKernel` again satisfies this property. </code>",
 "46":
 "<code>Algorithm.fin_measure.{u_1, u_2} {α : Type u_1} {β : Type u_2} [MeasurableSpace α] [TopologicalSpace α]\n  [OpensMeasurableSpace α] [MeasurableSpace β] [TopologicalSpace β] [BorelSpace β] (A : Algorithm α β) {f : α → β}\n  (hf : Continuous f) {n : ℕ} : Measure (iter α n)</code><span class=\"sep\"></span><code class=\"docstring\">The measure on finite sequences of iterations, defined by pushing forward `measure`\nalong the measurable function `frestrictLe n : (ℕ → α) → iter α n` that restricts\nthe infinite sequence to its first `n` elements. This is the measure that will be used\nthroughout the formalization. </code>",
 "45":
 "<code class=\"docstring\">`infer_instance` is an abbreviation for `exact inferInstance`.\nIt synthesizes a value of any target type by typeclass inference.\n</code>",
 "44":
 "<code class=\"docstring\">The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or\nnon-dependent hypotheses. It has many variants:\n- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.\n- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged\n  with the attribute `[simp]` and the given `hᵢ`'s, where the `hᵢ`'s are expressions.-\n- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated\n  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.\n- `simp [*]` simplifies the main goal target using the lemmas tagged with the\n  attribute `[simp]` and all hypotheses.\n- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.\n- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged\n  with the attribute `[simp]`, but removes the ones named `idᵢ`.\n- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If\n  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis\n  `hᵢ` is introduced, but the old one remains in the local context.\n- `simp at *` simplifies all the hypotheses and the target.\n- `simp [*] at *` simplifies target and all (propositional) hypotheses using the\n  other hypotheses.\n</code>",
 "43":
 "<code>Continuous.{u, v} {X : Type u} {Y : Type v} [TopologicalSpace X] [TopologicalSpace Y] (f : X → Y) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">A function between topological spaces is continuous if the preimage\nof every open set is open. Registered as a structure to make sure it is not unfolded by Lean. </code>",
 "42":
 "<code>BorelSpace.{u_6} (α : Type u_6) [TopologicalSpace α] [MeasurableSpace α] : Prop</code><span class=\"sep\"></span><code class=\"docstring\">A space with `MeasurableSpace` and `TopologicalSpace` structures such that\nthe `σ`-algebra of measurable sets is exactly the `σ`-algebra generated by open sets. </code>",
 "41": "<code>BorelSpace β</code>",
 "40": "<code>TopologicalSpace β</code>",
 "4":
 "<code>MeasurableSpace.{u_7} (α : Type u_7) : Type u_7</code><span class=\"sep\"></span><code class=\"docstring\">A measurable space is a space equipped with a σ-algebra. </code>",
 "39": "<code>MeasurableSpace β</code>",
 "38":
 "<code>OpensMeasurableSpace.{u_6} (α : Type u_6) [TopologicalSpace α] [h : MeasurableSpace α] : Prop</code><span class=\"sep\"></span><code class=\"docstring\">A space with `MeasurableSpace` and `TopologicalSpace` structures such that\nall open sets are measurable. </code>",
 "37": "<code>OpensMeasurableSpace α</code>",
 "36":
 "<code>TopologicalSpace.{u} (X : Type u) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">A topology on `X`. </code>",
 "35": "<code>TopologicalSpace α</code>",
 "34": "<code>MeasurableSpace α</code>",
 "33":
 "<code class=\"docstring\">A type universe. `Type ≡ Type 0`, `Type u ≡ Sort (u + 1)`. </code>",
 "32":
 "<code class=\"docstring\">`by tac` constructs a term of the expected type by running the tactic(s) `tac`. </code>",
 "31":
 "<code>ProbabilityTheory.Kernel.avg.{u_1, u_2} {α : Type u_1} {β : Type u_2} [MeasurableSpace α] [MeasurableSpace β]\n  (κ : Kernel α β) (μ : Measure α) : Measure β</code><span class=\"sep\"></span><code class=\"docstring\">The average of a kernel `κ` by a measure `μ`. Defined as `s↦ ∫⁻ a, κ a s ∂μ` </code>",
 "30":
 "<code>Algorithm.measure.{u_1, u_2} {α : Type u_1} {β : Type u_2} [MeasurableSpace α] [TopologicalSpace α]\n  [OpensMeasurableSpace α] [MeasurableSpace β] [TopologicalSpace β] [BorelSpace β] {f : α → β} (hf : Continuous f)\n  (A : Algorithm α β) : Measure (ℕ → α)</code><span class=\"sep\"></span><code class=\"docstring\">The measure on infinite sequences of iterations. It is constructed by first obtaining\na kernel from `iter α 0` to `ℕ → α` via the Ionescu-Tulcea theorem, and then averaging the kernel\nover the initial measure `A.ν_mequiv`. This gives a measure on the space of infinite sequences\nof points in `α`, which can be used to analyze the convergence properties of the algorithm. </code>",
 "3":
 "<code class=\"docstring\">The syntax `variable (X Y ... Z : Type*)` creates a new distinct implicit universe variable\n`&gt; 0` for each variable in the sequence. </code>",
 "29":
 "<code>MeasurableEquiv.funUnique.{u_8, u_9} (α : Type u_8) (β : Type u_9) [Unique α] [MeasurableSpace β] : (α → β) ≃ᵐ β</code><span class=\"sep\"></span><code class=\"docstring\">If `α` has a unique term, then the type of function `α → β` is measurably equivalent to `β`. </code>",
 "28":
 "<code>MeasureTheory.Measure.comap.{u_1, u_2} {α : Type u_1} {β : Type u_2} [MeasurableSpace α] [MeasurableSpace β] (f : α → β)\n  (μ : Measure β) : Measure α</code><span class=\"sep\"></span><code class=\"docstring\">Pullback of a `Measure`. If `f` sends each measurable set to a null-measurable set,\nthen for each measurable set `s` we have `comap f μ s = μ (f '' s)`.\n\nNote that if `f` is not injective, this definition assigns `Set.univ` measure zero. </code>",
 "27":
 "<code>Algorithm.ν_mequiv.{u_1, u_2} {α : Type u_1} {β : Type u_2} [MeasurableSpace α] [MeasurableSpace β]\n  (A : Algorithm α β) : Measure (iter α 0)</code><span class=\"sep\"></span><code class=\"docstring\">The measure `ν` that has been pulled back along the measurable equivalence\n`MeasurableEquiv.funUnique (iter α 0) α` to change the type of `ν` from\n`Measure α` to `Measure (iter α 0)`. </code>",
 "26":
 "<code>Continuous.measurable.{u_1, u_3} {α : Type u_1} {γ : Type u_3} [TopologicalSpace α] [MeasurableSpace α]\n  [OpensMeasurableSpace α] [TopologicalSpace γ] [MeasurableSpace γ] [BorelSpace γ] {f : α → γ} (hf : Continuous f) :\n  Measurable f</code><span class=\"sep\"></span><code class=\"docstring\">A continuous function from an `OpensMeasurableSpace` to a `BorelSpace`\nis measurable. </code>",
 "25": "<code>Continuous f</code>",
 "24":
 "<code>Tuple.measurable_prod_eval.{u_1, u_2} {α : Type u_1} {β : Type u_2} [MeasurableSpace α] [MeasurableSpace β] (n : ℕ)\n  {f : α → β} (hf : Measurable f) : Measurable (prod_eval n f)</code><span class=\"sep\"></span><code class=\"docstring\">For any measurable function `f : α → β`, the function `prod_eval n f` is measurable. </code>",
 "23": "<code>α → β</code>",
 "22":
 "<code>Tuple.prod_eval.{u_1, u_2} {α : Type u_1} {β : Type u_2} (n : ℕ) (f : α → β) (u : iter α n) :\n  iter α n × ({ x // x ∈ Finset.Iic n } → β)</code><span class=\"sep\"></span><code class=\"docstring\">Given `n`, a function `f : α → β` and a function `u : iter α n`,\nthis is the pair `(u, f ∘ u)`, where `f ∘ u` is the function\nfrom `Fin (n + 1)` to `β` that applies `f` to the values of `u`. </code>",
 "21":
 "<code>ProbabilityTheory.Kernel.comap.{u_1, u_2, u_4} {α : Type u_1} {β : Type u_2} {mα : MeasurableSpace α}\n  {mβ : MeasurableSpace β} {γ : Type u_4} {mγ : MeasurableSpace γ} (κ : Kernel α β) (g : γ → α) (hg : Measurable g) :\n  Kernel γ β</code><span class=\"sep\"></span><code class=\"docstring\">Pullback of a kernel, such that for each set s `comap κ g hg c s = κ (g c) s`.\nWe include measurability in the assumptions instead of using junk values\nto make sure that typeclass inference can infer that the `comap` of a Markov kernel\nis again a Markov kernel. </code>",
 "20": "<code>Algorithm α β</code>",
 "2": "<code>Type u_2</code>",
 "19":
 "<code>iter.{u_1} (α : Type u_1) (n : ℕ) : Type u_1</code><span class=\"sep\"></span><code class=\"docstring\">`iter α n` is the type of finite sequences of elements in `α` of length `n + 1`.\n\nIt represents the history of `n + 1` steps in an iterative process,\nwith entries indexed by `Fin (n + 1)` (i.e., from `0` to `n`).\n\nUsed in the context of stochastic iterative algorithms to store past evaluations or points. </code>",
 "18":
 "<code>Algorithm.iter_comap.{u_1, u_2} {α : Type u_1} {β : Type u_2} [MeasurableSpace α] [TopologicalSpace α]\n  [OpensMeasurableSpace α] [MeasurableSpace β] [TopologicalSpace β] [BorelSpace β] (A : Algorithm α β) {f : α → β}\n  (hf : Continuous f) (n : ℕ) : Kernel (iter α n) α</code><span class=\"sep\"></span><code class=\"docstring\">Given a continuous function `f : α → β` representing the evaluation (e.g., objective function),\nthis constructs a new kernel that maps a history of points (in `iter α n`)\nto a probability distribution over the next point in `α`.\n\nThe original algorithm `A` provides a transition kernel `A.kernel_iter n` that depends on\nboth the previously proposed points and their corresponding evaluations.\nHowever, in practice, the algorithm itself only generates the sequence of points,\nand the evaluations are computed externally by applying `f` to each point.\n\nThe function `prod_eval n f` deterministically reconstructs the full history\n(points and their evaluations) from the point sequence alone, using `f` and\nthe `comap` pulls back the original kernel along this map,\nresulting in a kernel that operates directly on the sequence of points. </code>",
 "17":
 "<code>ProbabilityTheory.Kernel.traj.{u_1} {X : ℕ → Type u_1} [(n : ℕ) → MeasurableSpace (X n)]\n  (κ : (n : ℕ) → Kernel ((i : { x // x ∈ Finset.Iic n }) → X ↑i) (X (n + 1))) [∀ (n : ℕ), IsMarkovKernel (κ n)]\n  (a : ℕ) : Kernel ((i : { x // x ∈ Finset.Iic a }) → X ↑i) ((n : ℕ) → X n)</code><span class=\"sep\"></span><code class=\"docstring\">*Ionescu-Tulcea Theorem* : Given a family of kernels `κ n` taking variables in `Iic n` with\nvalue in `X (n + 1)`, the kernel `traj κ a` takes a variable `x` depending on the\nvariables `i ≤ a` and associates to it a kernel on trajectories depending on all variables,\nwhere the entries with index `≤ a` are those of `x`, and then one follows iteratively the\nkernels `κ a`, then `κ (a + 1)`, and so on.\n\nThe fact that such a kernel exists on infinite trajectories is not obvious, and is the content of\nthe Ionescu-Tulcea theorem. </code>",
 "16": "<code>(n : ℕ) → Kernel (prod_iter_image α β n) α</code>",
 "159":
 "<code class=\"docstring\">`linarith` attempts to find a contradiction between hypotheses that are linear (in)equalities.\nEquivalently, it can prove a linear inequality by assuming its negation and proving `False`.\n\nIn theory, `linarith` should prove any goal that is true in the theory of linear arithmetic over\nthe rationals. While there is some special handling for non-dense orders like `Nat` and `Int`,\nthis tactic is not complete for these theories and will not prove every true goal. It will solve\ngoals over arbitrary types that instantiate `LinearOrderedCommRing`.\n\nAn example:\n```lean\nexample (x y z : ℚ) (h1 : 2*x &lt; 3*y) (h2 : -4*x + 2*z &lt; 0)\n        (h3 : 12*y - 4* z &lt; 0) : False := by\n  linarith\n```\n\n`linarith` will use all appropriate hypotheses and the negation of the goal, if applicable.\nDisequality hypotheses require case splitting and are not normally considered\n(see the `splitNe` option below).\n\n`linarith [t1, t2, t3]` will additionally use proof terms `t1, t2, t3`.\n\n`linarith only [h1, h2, h3, t1, t2, t3]` will use only the goal (if relevant), local hypotheses\n`h1`, `h2`, `h3`, and proofs `t1`, `t2`, `t3`. It will ignore the rest of the local context.\n\n`linarith!` will use a stronger reducibility setting to try to identify atoms. For example,\n```lean\nexample (x : ℚ) : id x ≥ x := by\n  linarith\n```\nwill fail, because `linarith` will not identify `x` and `id x`. `linarith!` will.\nThis can sometimes be expensive.\n\n`linarith (config := { .. })` takes a config object with five\noptional arguments:\n* `discharger` specifies a tactic to be used for reducing an algebraic equation in the\n  proof stage. The default is `ring`. Other options include `simp` for basic\n  problems.\n* `transparency` controls how hard `linarith` will try to match atoms to each other. By default\n  it will only unfold `reducible` definitions.\n* If `splitHypotheses` is true, `linarith` will split conjunctions in the context into separate\n  hypotheses.\n* If `splitNe` is `true`, `linarith` will case split on disequality hypotheses.\n  For a given `x ≠ y` hypothesis, `linarith` is run with both `x &lt; y` and `x &gt; y`,\n  and so this runs linarith exponentially many times with respect to the number of\n  disequality hypotheses. (`false` by default.)\n* If `exfalso` is `false`, `linarith` will fail when the goal is neither an inequality nor `False`.\n  (`true` by default.)\n* `restrict_type` (not yet implemented in mathlib4)\n  will only use hypotheses that are inequalities over `tp`. This is useful\n  if you have e.g. both integer and rational valued inequalities in the local context, which can\n  sometimes confuse the tactic.\n\nA variant, `nlinarith`, does some basic preprocessing to handle some nonlinear goals.\n\nThe option `set_option trace.linarith true` will trace certain intermediate stages of the `linarith`\nroutine.\n</code>",
 "158": "<code>fmax hf &lt; fmax ⋯</code>",
 "157":
 "<code>fmax._proof_1.{u_1, u_2} {α : Type u_1} [PseudoMetricSpace α] {β : Type u_2} [PseudoMetricSpace β] {f : α → β}\n  (hf : Lipschitz f) : Continuous f</code>",
 "156":
 "<code>congrArg.{u, v} {α : Sort u} {β : Sort v} {a₁ a₂ : α} (f : α → β) (h : a₁ = a₂) : f a₁ = f a₂</code><span class=\"sep\"></span><code class=\"docstring\">Congruence in the function argument: if `a₁ = a₂` then `f a₁ = f a₂` for\nany (nondependent) function `f`. This is more powerful than it might look at first, because\nyou can also use a lambda expression for `f` to prove that\n`&lt;something containing a₁&gt; = &lt;something containing a₂&gt;`. This function is used\ninternally by tactics like `congr` and `simp` to apply equalities inside\nsubterms.\n\nFor more information: [Equality](https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#equality)\n</code>",
 "155":
 "<code>id.{u} {α : Sort u} (a : α) : α</code><span class=\"sep\"></span><code class=\"docstring\">The identity function. `id` takes an implicit argument `α : Sort u`\n(a type in any universe), and an argument `a : α`, and returns `a`.\n\nAlthough this may look like a useless function, one application of the identity\nfunction is to explicitly put a type on an expression. If `e` has type `T`,\nand `T'` is definitionally equal to `T`, then `@id T' e` typechecks, and Lean\nknows that this expression has type `T'` rather than `T`. This can make a\ndifference for typeclass inference, since `T` and `T'` may have different\ntypeclass instances on them. `show T' from e` is sugar for an `@id T' e`\nexpression.\n</code>",
 "154":
 "<code>Eq.mpr.{u} {α β : Sort u} (h : α = β) (b : β) : α</code><span class=\"sep\"></span><code class=\"docstring\">If `h : α = β` is a proof of type equality, then `h.mpr : β → α` is the induced\n\"cast\" operation in the reverse direction, mapping elements of `β` to elements of `α`.\n\nYou can prove theorems about the resulting element by induction on `h`, since\n`rfl.mpr` is definitionally the identity function.\n</code>",
 "153": "<code>fmax ⋯ ≤ fmax hf</code>",
 "152":
 "<code>Lipschitz.f_tilde_apply_out.{u_1} {α : Type u_1} [NormedAddCommGroup α] [CompactSpace α] [Nonempty α] {f : α → ℝ}\n  (hf : Lipschitz f) (c : α) {ε : ℝ} {x : α} (hx : x ∉ ball c (ε / 2)) : hf.f_tilde c ε x = f x</code>",
 "151":
 "<code class=\"docstring\">The `have` tactic is for adding hypotheses to the local context of the main goal.\n* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.\n* `have h := e` uses the type of `e` for `t`.\n* `have : t := e` and `have := e` use `this` for the name of the hypothesis.\n* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,\n  where `_` stands for the tactics that follow this one.\n  It is convenient for types that have only one applicable constructor.\n  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the\n  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.\n</code>",
 "150":
 "<code>False : Prop</code><span class=\"sep\"></span><code class=\"docstring\">`False` is the empty proposition. Thus, it has no introduction rules.\nIt represents a contradiction. `False` elimination rule, `False.rec`,\nexpresses the fact that anything follows from a contradiction.\nThis rule is sometimes called ex falso (short for ex falso sequitur quodlibet),\nor the principle of explosion.\nFor more information: [Propositional Logic](https://lean-lang.org/theorem_proving_in_lean4/propositions_and_proofs.html#propositional-logic)\n</code>",
 "15":
 "<code>ProbabilityTheory.IsMarkovKernel.{u_1, u_2} {α : Type u_1} {β : Type u_2} {mα : MeasurableSpace α}\n  {mβ : MeasurableSpace β} (κ : Kernel α β) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">A kernel is a Markov kernel if every measure in its image is a probability measure. </code>",
 "149": "<code>x' ∉ ball c (ε / 2)</code>",
 "148":
 "<code class=\"docstring\">`by_contra h` proves `⊢ p` by contradiction,\nintroducing a hypothesis `h : ¬p` and proving `False`.\n* If `p` is a negation `¬q`, `h : q` will be introduced instead of `¬¬q`.\n* If `p` is decidable, it uses `Decidable.byContradiction` instead of `Classical.byContradiction`.\n* If `h` is omitted, the introduced variable `_: ¬p` will be anonymous.\n</code>",
 "147":
 "<code>Lipschitz.max_f_tilde_in_ball.{u_1} {α : Type u_1} [NormedAddCommGroup α] [CompactSpace α] [Nonempty α] {f : α → ℝ}\n  (hf : Lipschitz f) (c : α) [NormedSpace ℝ α] {ε : ℝ} (ε_pos : 0 &lt; ε) : compact_argmax ⋯ ∈ ball c (ε / 2)</code>",
 "146":
 "<code>compact_argmax_apply.{u_1, u_2} {α : Type u_1} {β : Type u_2} [TopologicalSpace α] [Nonempty α] [CompactSpace α]\n  [TopologicalSpace β] [LinearOrder β] {f : α → β} [ClosedIciTopology β] (hf : Continuous f) (y : α) :\n  f y ≤ f (compact_argmax hf)</code>",
 "145":
 "<code>lt_of_le_of_lt'.{u_1} {α : Type u_1} [Preorder α] {a b c : α} : b ≤ a → c &lt; b → c &lt; a</code>",
 "144": "<code>fmax hf &lt; hf.f_tilde c ε c</code>",
 "143":
 "<code>Lipschitz.max_f_lt_max_f_tilde.{u_1} {α : Type u_1} [NormedAddCommGroup α] [CompactSpace α] [Nonempty α] {f : α → ℝ}\n  (hf : Lipschitz f) (c : α) [NormedSpace ℝ α] {ε : ℝ} (ε_pos : 0 &lt; ε) : fmax hf &lt; fmax ⋯</code>",
 "142":
 "<code>Lipschitz.max_f_lt_f_tilde_c.{u_1} {α : Type u_1} [NormedAddCommGroup α] [CompactSpace α] [Nonempty α] {f : α → ℝ}\n  (hf : Lipschitz f) (c : α) {ε : ℝ} (ε_pos : 0 &lt; ε) : fmax hf &lt; hf.f_tilde c ε c</code>",
 "141":
 "<code>Lipschitz.dist_left.{u_1} {α : Type u_1} [PseudoMetricSpace α] (y : α) : Lipschitz fun x =&gt; dist x y</code>",
 "140":
 "<code>Lipschitz.div_const.{u_1} {α : Type u_1} [PseudoEMetricSpace α] {f : α → ℝ} (hf : Lipschitz f) {b : ℝ} :\n  Lipschitz fun a =&gt; f a / b</code>",
 "14":
 "<code>Algorithm.markov_kernel.{u_1, u_2} {α : Type u_1} {β : Type u_2} [MeasurableSpace α] [MeasurableSpace β]\n  (self : Algorithm α β) (n : ℕ) : IsMarkovKernel (self.kernel_iter n)</code>",
 "139":
 "<code>lipschitz_const.{u_1, u_2} {α : Type u_1} {β : Type u_2} [PseudoEMetricSpace β] [PseudoEMetricSpace α] {b : β} :\n  Lipschitz fun x =&gt; b</code>",
 "138":
 "<code>Lipschitz.sub.{u_1, u_2} {α : Type u_1} {β : Type u_2} [PseudoEMetricSpace α] {f g : α → β} [SeminormedAddCommGroup β]\n  (hf : Lipschitz f) (hg : Lipschitz g) : Lipschitz (f - g)</code>",
 "137":
 "<code>Lipschitz.mul_const.{u_1} {α : Type u_1} [PseudoEMetricSpace α] {f : α → ℝ} (hf : Lipschitz f) {b : ℝ} :\n  Lipschitz fun a =&gt; f a * b</code>",
 "136":
 "<code>Lipschitz.const_mul.{u_1} {α : Type u_1} [PseudoEMetricSpace α] {f : α → ℝ} (hf : Lipschitz f) {b : ℝ} :\n  Lipschitz fun a =&gt; b * f a</code>",
 "135": "<code>Ne.symm.{u} {α : Sort u} {a b : α} (h : a ≠ b) : b ≠ a</code>",
 "134":
 "<code>half_pos.{u_2} {α : Type u_2} [Semifield α] [LinearOrder α] [IsStrictOrderedRing α] {a : α} (h : 0 &lt; a) : 0 &lt; a / 2</code>",
 "133":
 "<code>ne_of_lt.{u_1} {α : Type u_1} [Preorder α] {a b : α} (h : a &lt; b) : a ≠ b</code>",
 "132":
 "<code>CommGroupWithZero.mul_inv_cancel.{u_2} {G₀ : Type u_2} [self : CommGroupWithZero G₀] (a : G₀) : a ≠ 0 → a * a⁻¹ = 1</code><span class=\"sep\"></span><code class=\"docstring\">Every nonzero element of a group with zero is invertible. </code>",
 "131":
 "<code class=\"docstring\">`exact e` closes the main goal if its target type matches that of `e`.\n</code>",
 "130":
 "<code class=\"docstring\">Tactic for evaluating expressions in *commutative* (semi)rings, allowing for variables in the\nexponent. If the goal is not appropriate for `ring` (e.g. not an equality) `ring_nf` will be\nsuggested.\n\n* `ring!` will use a more aggressive reducibility setting to determine equality of atoms.\n* `ring1` fails if the target is not an equality.\n\nFor example:\n```\nexample (n : ℕ) (m : ℤ) : 2^(n+1) * m = 2 * 2^n * m := by ring\nexample (a b : ℤ) (n : ℕ) : (a + b)^(n + 2) = (a^2 + b^2 + a * b + b * a) * (a + b)^n := by ring\nexample (x y : ℕ) : x + id y = y + id x := by ring!\nexample (x : ℕ) (h : x * 2 &gt; 5): x + x &gt; 5 := by ring; assumption -- suggests ring_nf\n```\n</code>",
 "13":
 "<code>prod_iter_image.{u_1, u_2} (α : Type u_1) (β : Type u_2) (n : ℕ) : Type (max u_1 u_2)</code><span class=\"sep\"></span><code class=\"docstring\">`prod_iter_image α β n` is the input space of the algorithm at iteration `n`.\n\nIt consists of:\n- a sequence of `n + 1` past points in `α`,\n- and their corresponding evaluations in `β`.\n\nThis pair encodes the full information available up to iteration `n`. </code>",
 "129": "<code>ε / 2 / (ε / 2) = 1</code>",
 "128":
 "<code class=\"docstring\">Given a main goal `ctx ⊢ t`, `suffices h : t' from e` replaces the main goal with `ctx ⊢ t'`,\n`e` must have type `t` in the context `ctx, h : t'`.\n\nThe variant `suffices h : t' by tac` is a shorthand for `suffices h : t' from by tac`.\nIf `h :` is omitted, the name `this` is used.\n </code>",
 "127":
 "<code class=\"docstring\">`rw` is like `rewrite`, but also tries to close the goal by \"cheap\" (reducible) `rfl` afterwards.\n</code>",
 "126": "<code>a ∈ sphere c (ε / 2)</code>",
 "125":
 "<code class=\"docstring\">Introduces one or more hypotheses, optionally naming and/or pattern-matching them.\nFor each hypothesis to be introduced, the remaining main goal's target type must\nbe a `let` or function type.\n\n* `intro` by itself introduces one anonymous hypothesis, which can be accessed\n  by e.g. `assumption`.\n* `intro x y` introduces two hypotheses and names them. Individual hypotheses\n  can be anonymized via `_`, or matched against a pattern:\n  ```lean\n  -- ... ⊢ α × β → ...\n  intro (a, b)\n  -- ..., a : α, b : β ⊢ ...\n  ```\n* Alternatively, `intro` can be combined with pattern matching much like `fun`:\n  ```lean\n  intro\n  | n + 1, 0 =&gt; tac\n  | ...\n  ```\n</code>",
 "124":
 "<code>HAdd.hAdd.{u, v, w} {α : Type u} {β : Type v} {γ : outParam (Type w)} [self : HAdd α β γ] : α → β → γ</code><span class=\"sep\"></span><code class=\"docstring\">`a + b` computes the sum of `a` and `b`.\nThe meaning of this notation is type-dependent. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `+` in identifiers is `add`.</code>",
 "123":
 "<code>HSub.hSub.{u, v, w} {α : Type u} {β : Type v} {γ : outParam (Type w)} [self : HSub α β γ] : α → β → γ</code><span class=\"sep\"></span><code class=\"docstring\">`a - b` computes the difference of `a` and `b`.\nThe meaning of this notation is type-dependent.\n* For natural numbers, this operator saturates at 0: `a - b = 0` when `a ≤ b`. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `-` in identifiers is `sub` (when used as a binary operator).</code>",
 "122":
 "<code>HMul.hMul.{u, v, w} {α : Type u} {β : Type v} {γ : outParam (Type w)} [self : HMul α β γ] : α → β → γ</code><span class=\"sep\"></span><code class=\"docstring\">`a * b` computes the product of `a` and `b`.\nThe meaning of this notation is type-dependent. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `*` in identifiers is `mul`.</code>",
 "121":
 "<code>HDiv.hDiv.{u, v, w} {α : Type u} {β : Type v} {γ : outParam (Type w)} [self : HDiv α β γ] : α → β → γ</code><span class=\"sep\"></span><code class=\"docstring\">`a / b` computes the result of dividing `a` by `b`.\nThe meaning of this notation is type-dependent.\n* For most types like `Nat`, `Int`, `Rat`, `Real`, `a / 0` is defined to be `0`.\n* For `Nat`, `a / b` rounds downwards.\n* For `Int`, `a / b` rounds downwards if `b` is positive or upwards if `b` is negative.\n  It is implemented as `Int.ediv`, the unique function satisfying\n  `a % b + b * (a / b) = a` and `0 ≤ a % b &lt; natAbs b` for `b ≠ 0`.\n  Other rounding conventions are available using the functions\n  `Int.fdiv` (floor rounding) and `Int.tdiv` (truncation rounding).\n* For `Float`, `a / 0` follows the IEEE 754 semantics for division,\n  usually resulting in `inf` or `nan`. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `/` in identifiers is `div`.</code>",
 "120":
 "<code>Metric.sphere.{u} {α : Type u} [PseudoMetricSpace α] (x : α) (ε : ℝ) : Set α</code><span class=\"sep\"></span><code class=\"docstring\">`sphere x ε` is the set of all points `y` with `dist y x = ε` </code>",
 "12":
 "<code>ProbabilityTheory.Kernel.{u_1, u_2} (α : Type u_1) (β : Type u_2) [MeasurableSpace α] [MeasurableSpace β] :\n  Type (max u_1 u_2)</code><span class=\"sep\"></span><code class=\"docstring\">A kernel from a measurable space `α` to another measurable space `β` is a measurable function\n`κ : α → Measure β`. The measurable space structure on `MeasureTheory.Measure β` is given by\n`MeasureTheory.Measure.instMeasurableSpace`. A map `κ : α → MeasureTheory.Measure β` is measurable\niff `∀ s : Set β, MeasurableSet s → Measurable (fun a ↦ κ a s)`. </code>",
 "119":
 "<code>Lipschitz.if.{u_1} {α : Type u_1} [NormedAddCommGroup α] [NormedSpace ℝ α] {f g : α → ℝ} {c : α} {ε : ℝ}\n  [(a : α) → Decidable (a ∈ ball c ε)] (hp : ∀ a ∈ sphere c ε, g a = 0) (hf : Lipschitz f) (hg : Lipschitz g) :\n  Lipschitz fun a =&gt; if a ∈ ball c ε then f a + g a else f a</code>",
 "118":
 "<code class=\"docstring\">`refine e` behaves like `exact e`, except that named (`?x`) or unnamed (`?_`)\nholes in `e` that are not solved by unification with the main goal's target type\nare converted into new goals, using the hole's name, if any, as the goal case name.\n</code>",
 "117":
 "<code>LT.lt.{u} {α : Type u} [self : LT α] : α → α → Prop</code><span class=\"sep\"></span><code class=\"docstring\">The less-than relation: `x &lt; y` \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `&lt;` in identifiers is `lt`.</code>",
 "116": "<code>0 &lt; ε</code>",
 "115":
 "<code>Lipschitz.f_tilde_lipschitz.{u_1} {α : Type u_1} [NormedAddCommGroup α] [CompactSpace α] [Nonempty α] {f : α → ℝ}\n  (hf : Lipschitz f) (c : α) [NormedSpace ℝ α] {ε : ℝ} (ε_pos : 0 &lt; ε) : Lipschitz (hf.f_tilde c ε)</code>",
 "114":
 "<code>fmin.{u_1, u_2} {α : Type u_1} [PseudoMetricSpace α] {β : Type u_2} [CompactSpace α] [Nonempty α] [PseudoMetricSpace β]\n  [LinearOrder β] [ClosedIicTopology β] {f : α → β} (hf : Lipschitz f) : β</code><span class=\"sep\"></span><code class=\"docstring\">The minimum of a Lipschitz function over `α`. </code>",
 "113":
 "<code>Metric.ball.{u} {α : Type u} [PseudoMetricSpace α] (x : α) (ε : ℝ) : Set α</code><span class=\"sep\"></span><code class=\"docstring\">`ball x ε` is the set of all points `y` with `dist y x &lt; ε` </code>",
 "112":
 "<code class=\"docstring\">`if c then t else e` is notation for `ite c t e`, \"if-then-else\", which decides to\nreturn `t` or `e` depending on whether `c` is true or false. The explicit argument\n`c : Prop` does not have any actual computational content, but there is an additional\n`[Decidable c]` argument synthesized by typeclass inference which actually\ndetermines how to evaluate `c` to true or false. Write `if h : c then t else e`\ninstead for a \"dependent if-then-else\" `dite`, which allows `t`/`e` to use the fact\nthat `c` is true/false.\n</code>",
 "111":
 "<code>Lipschitz.f_tilde.{u_1} {α : Type u_1} [NormedAddCommGroup α] [CompactSpace α] [Nonempty α] {f : α → ℝ}\n  (hf : Lipschitz f) (c : α) (ε : ℝ) (x : α) : ℝ</code><span class=\"sep\"></span><code class=\"docstring\">Given a `Lipschitz` function `f` over a `CompactSpace α`, construct a `Lipschitz`\nfunction (see `Lipschitz.f_tilde_lipschitz`) that is indistinguishable from `f` outside\nof a ball of radius `ε` such that the maximum of this new function is greater than the\nmaximum of `f` and is located in the ball. </code>",
 "110":
 "<code>Iff (a b : Prop) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">If and only if, or logical bi-implication. `a ↔ b` means that `a` implies `b` and vice versa.\nBy `propext`, this implies that `a` and `b` are equal and hence any expression involving `a`\nis equivalent to the corresponding expression with `b` instead.\n\n\nConventions for notations in identifiers:\n\n * The recommended spelling of `↔` in identifiers is `iff`.\n\n * The recommended spelling of `&lt;-&gt;` in identifiers is `iff` (prefer `↔` over `&lt;-&gt;`).</code>",
 "11": "<code>ℕ</code>",
 "109":
 "<code>Nonempty.{u} (α : Sort u) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">`Nonempty α` is a typeclass that says that `α` is not an empty type,\nthat is, there exists an element in the type. It differs from `Inhabited α`\nin that `Nonempty α` is a `Prop`, which means that it does not actually carry\nan element of `α`, only a proof that *there exists* such an element.\nGiven `Nonempty α`, you can construct an element of `α` *nonconstructively*\nusing `Classical.choice`.\n</code>",
 "108": "<code>Nonempty α</code>",
 "107":
 "<code>CompactSpace.{u_1} (X : Type u_1) [TopologicalSpace X] : Prop</code><span class=\"sep\"></span><code class=\"docstring\">Type class for compact spaces. Separation is sometimes included in the definition, especially\nin the French literature, but we do not include it here. </code>",
 "106": "<code>CompactSpace α</code>",
 "105":
 "<code>Real : Type</code><span class=\"sep\"></span><code class=\"docstring\">The type `ℝ` of real numbers constructed as equivalence classes of Cauchy sequences of rational\nnumbers. </code>",
 "104":
 "<code>NormedSpace.{u_6, u_7} (𝕜 : Type u_6) (E : Type u_7) [NormedField 𝕜] [SeminormedAddCommGroup E] : Type (max u_6 u_7)</code><span class=\"sep\"></span><code class=\"docstring\">A normed space over a normed field is a vector space endowed with a norm which satisfies the\nequality `‖c • x‖ = ‖c‖ ‖x‖`. We require only `‖c • x‖ ≤ ‖c‖ ‖x‖` in the definition, then prove\n`‖c • x‖ = ‖c‖ ‖x‖` in `norm_smul`.\n\nNote that since this requires `SeminormedAddCommGroup` and not `NormedAddCommGroup`, this\ntypeclass can be used for \"semi normed spaces\" too, just as `Module` can be used for\n\"semi modules\". </code>",
 "103": "<code>NormedSpace ℝ α</code>",
 "102":
 "<code>NormedAddCommGroup.{u_8} (E : Type u_8) : Type u_8</code><span class=\"sep\"></span><code class=\"docstring\">A normed group is an additive group endowed with a norm for which `dist x y = ‖x - y‖` defines a\nmetric space structure. </code>",
 "101": "<code>NormedAddCommGroup α</code>",
 "100": "<code>α → ℝ</code>",
 "10":
 "<code>Algorithm.kernel_iter.{u_1, u_2} {α : Type u_1} {β : Type u_2} [MeasurableSpace α] [MeasurableSpace β]\n  (self : Algorithm α β) (n : ℕ) : Kernel (prod_iter_image α β n) α</code>",
 "1": "<code>Type u_1</code>",
 "0":
 "<code>Algorithm.{u_1, u_2} (α : Type u_1) (β : Type u_2) [MeasurableSpace α] [MeasurableSpace β] : Type (max u_1 u_2)</code><span class=\"sep\"></span><code class=\"docstring\">`Algorithm α β` represents a general iterative stochastic optimization algorithm.\n\nIt models a sequence of updates where:\n- `α` is the search space (e.g., parameters, candidate solutions),\n- `β` is the evaluation space (e.g., objective values, feedback),\n- `ν` is the initial probability measure over `α` (the starting distribution of candidates),\n- `kernel_iter n` is a Markov kernel that outputs a new candidate in `α`\n  given the history of the first `n` points and their evaluations,\n  i.e., from the space `prod_iter_image α β n` = (`α × β`)ⁿ,\n- `markov_kernel n` asserts that each such `kernel_iter n` is a valid Markov kernel.\n\nIt allows formal reasoning over joint distributions of evaluated points and convergence\nproperties. </code>"}